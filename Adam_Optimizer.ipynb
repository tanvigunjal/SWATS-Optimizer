{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXHEg4ifFYxyBT8m1OvtOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvigunjal/SWATS-Optimizer/blob/main/Adam_Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE8fxUBMWAXW",
        "outputId": "53282f49-df5e-4f34-b05e-dfbec7832c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "#Check device (cuda or CPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVgC1pPyWVDy",
        "outputId": "7000284f-be11-4b96-e996-89f5db523c38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transforms \n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.4914, 0.4822, 0.4465], std = [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.4914, 0.4822, 0.4465], std = [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "#Hyperparameters\n",
        "batch_size = 128\n",
        "num_epochs = 200\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n"
      ],
      "metadata": {
        "id": "5Kv2YJcTWniM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset \n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "#split trainset into train and validation \n",
        "train_ds, val_ds = random_split(trainset, [int(0.8*len(trainset)), int(00.2*len(trainset))])\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))\n",
        "print(len(testset))\n",
        "\n",
        "#Dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2, pin_memory = True)\n",
        "validation_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2, pin_memory = True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2, pin_memory = True)\n",
        "\n",
        "\n",
        "#image classes \n",
        "num_classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JErrIxIWW4y8",
        "outputId": "776cc3d3-e1eb-46a6-8500-729f5556133a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "40000\n",
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet Model\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion*planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(self.expansion*planes)\n",
        "      )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BottleNeck, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes , planes, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion*planes :\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(self.expansion*planes)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = F.relu(self.bn2(self.conv2(out)))\n",
        "    out = self.bn3(self.conv3(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1]*(num_blocks-1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes * block.expansion      \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = F.avg_pool2d(out, 4)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out\n",
        "\n",
        "#ResNet18 = ResNet(BasicBlock, [2,2,2,2])\n",
        "ResNet34 = ResNet(BasicBlock, [3,4,6,3]).to(device)\n",
        "#ResNet50 = ResNet(BottleNeck, [3,4,6,3])\n",
        "#ResNet101 = ResNet(BottleNeck, [3,4,23,3])\n",
        "#ResNet152 = ResNet(BottleNeck, [3,8,36,3])\n",
        "\n",
        "print(ResNet34)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeOOf-NuW_UG",
        "outputId": "f4acb1b0-f274-478b-df28-68ab43955027"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Optimizer\n",
        "#optimizer = SwatsVanillaGlobal(ResNet34.parameters())\n",
        "optimizer = optim.Adam(ResNet34.parameters(), lr= learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
      ],
      "metadata": {
        "id": "Y3LBaRUFXDoU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training(model, train_loader, validation_loader, criterion, optimizer, set_device):\n",
        "  best_accuracy = 0\n",
        "  train_loss_history = []\n",
        "  validation_loss_history = []\n",
        "  training_acc_history = []\n",
        "  validation_acc_history = []\n",
        "\n",
        "  for epoch in range(0, num_epochs):\n",
        "    model.train()\n",
        "    train_loss_scores = []\n",
        "    training_acc_scores = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for batch_index, (images, targets) in enumerate(train_loader):\n",
        "      images = images.to(set_device)\n",
        "      targets = targets.to(set_device)\n",
        "      \n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, targets)\n",
        "      train_loss_scores.append(loss.item())\n",
        "      \n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      correct_predictions = (preds==targets).sum().item()\n",
        "      training_acc_scores.append(correct_predictions/targets.shape[0])\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      lr=optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "      if (batch_index+1) % 100 == 0:\n",
        "        print(f\"Epoch : [{epoch+1}/{num_epochs}] | Step : [{batch_index+1}/{len(train_loader)}] | Loss : {loss.item()} \")\n",
        "            \n",
        "    train_loss_history.append((sum(train_loss_scores)/len(train_loss_scores)))\n",
        "    training_acc_history.append((sum(training_acc_scores)/len(training_acc_scores))*100)      \n",
        "    print(f'Epoch : {epoch+1} | Loss : {train_loss_history[-1]} | Training Accuracy : {training_acc_history[-1]}% | Learning rate : {lr}')\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      correct_predictions = 0\n",
        "      validation_acc_scores = []\n",
        "      validation_loss_scores = []\n",
        "\n",
        "      for images, targets in iter(validation_loader):\n",
        "        images = images.to(set_device)\n",
        "        targets = targets.to(set_device)\n",
        "                    \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, targets)\n",
        "        validation_loss_scores.append(loss.item())\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_predictions = (preds == targets).sum().item()\n",
        "        validation_acc_scores.append(correct_predictions/targets.shape[0])\n",
        "\n",
        "      validation_loss_history.append((sum(validation_loss_scores)/len(validation_loss_scores)))\n",
        "      validation_acc_history.append((sum(validation_acc_scores)/len(validation_acc_scores))*100)\n",
        "      print(f'Epoch {epoch+1} | Validation Accuracy {validation_acc_history[-1]}%')\n",
        "\n",
        "      #Early stopping\n",
        "      if validation_acc_history[-1]>best_accuracy:\n",
        "        best_accuracy = validation_acc_history[-1]\n",
        "        print('Saving the model...')\n",
        "        torch.save(model.state_dict(), f\"/content/gdrive/MyDrive/Optimization/Accuracy_{best_accuracy}_batchsize_{batch_size}_lr_{learning_rate}.ckpt\")\n",
        "\n",
        "  return train_loss_history, validation_loss_history, training_acc_history, validation_acc_history"
      ],
      "metadata": {
        "id": "YvOLKtxOXJh9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, validation_loss, train_acc, validation_acc = model_training(ResNet34, train_loader, validation_loader, criterion, optimizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0FwQs6yXN5d",
        "outputId": "fe59c787-8c5e-481b-f0bd-e1f95da8c1e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : [1/200] | Step : [100/313] | Loss : 1.7122137546539307 \n",
            "Epoch : [1/200] | Step : [200/313] | Loss : 1.6789543628692627 \n",
            "Epoch : [1/200] | Step : [300/313] | Loss : 1.3436992168426514 \n",
            "Epoch : 1 | Loss : 1.69094885081148 | Training Accuracy : 37.50499201277955% | Learning rate : 0.001\n",
            "Epoch 1 | Validation Accuracy 47.151898734177216%\n",
            "Saving the model...\n",
            "Epoch : [2/200] | Step : [100/313] | Loss : 1.3629848957061768 \n",
            "Epoch : [2/200] | Step : [200/313] | Loss : 1.3286736011505127 \n",
            "Epoch : [2/200] | Step : [300/313] | Loss : 1.139847755432129 \n",
            "Epoch : 2 | Loss : 1.2347631648706552 | Training Accuracy : 54.88468450479233% | Learning rate : 0.001\n",
            "Epoch 2 | Validation Accuracy 54.7567246835443%\n",
            "Saving the model...\n",
            "Epoch : [3/200] | Step : [100/313] | Loss : 1.1417690515518188 \n",
            "Epoch : [3/200] | Step : [200/313] | Loss : 0.9192209243774414 \n",
            "Epoch : [3/200] | Step : [300/313] | Loss : 1.0824787616729736 \n",
            "Epoch : 3 | Loss : 0.9845813771787162 | Training Accuracy : 65.20067891373802% | Learning rate : 0.001\n",
            "Epoch 3 | Validation Accuracy 65.67444620253164%\n",
            "Saving the model...\n",
            "Epoch : [4/200] | Step : [100/313] | Loss : 0.8583160638809204 \n",
            "Epoch : [4/200] | Step : [200/313] | Loss : 0.7070931792259216 \n",
            "Epoch : [4/200] | Step : [300/313] | Loss : 0.5934396386146545 \n",
            "Epoch : 4 | Loss : 0.8256611753576479 | Training Accuracy : 70.75928514376997% | Learning rate : 0.001\n",
            "Epoch 4 | Validation Accuracy 68.36431962025317%\n",
            "Saving the model...\n",
            "Epoch : [5/200] | Step : [100/313] | Loss : 0.6846877336502075 \n",
            "Epoch : [5/200] | Step : [200/313] | Loss : 0.8198907971382141 \n",
            "Epoch : [5/200] | Step : [300/313] | Loss : 0.6904951333999634 \n",
            "Epoch : 5 | Loss : 0.7007565465978921 | Training Accuracy : 75.46176118210862% | Learning rate : 0.001\n",
            "Epoch 5 | Validation Accuracy 75.10878164556962%\n",
            "Saving the model...\n",
            "Epoch : [6/200] | Step : [100/313] | Loss : 0.5855806469917297 \n",
            "Epoch : [6/200] | Step : [200/313] | Loss : 0.7191019654273987 \n",
            "Epoch : [6/200] | Step : [300/313] | Loss : 0.6514127254486084 \n",
            "Epoch : 6 | Loss : 0.6123968978849844 | Training Accuracy : 78.72404153354633% | Learning rate : 0.001\n",
            "Epoch 6 | Validation Accuracy 75.82080696202532%\n",
            "Saving the model...\n",
            "Epoch : [7/200] | Step : [100/313] | Loss : 0.5619754195213318 \n",
            "Epoch : [7/200] | Step : [200/313] | Loss : 0.5170072317123413 \n",
            "Epoch : [7/200] | Step : [300/313] | Loss : 0.49423953890800476 \n",
            "Epoch : 7 | Loss : 0.5501498712327915 | Training Accuracy : 80.89307108626198% | Learning rate : 0.001\n",
            "Epoch 7 | Validation Accuracy 75.97903481012658%\n",
            "Saving the model...\n",
            "Epoch : [8/200] | Step : [100/313] | Loss : 0.42951345443725586 \n",
            "Epoch : [8/200] | Step : [200/313] | Loss : 0.3761212229728699 \n",
            "Epoch : [8/200] | Step : [300/313] | Loss : 0.4833262860774994 \n",
            "Epoch : 8 | Loss : 0.4926156389256255 | Training Accuracy : 83.02466054313099% | Learning rate : 0.001\n",
            "Epoch 8 | Validation Accuracy 79.88528481012658%\n",
            "Saving the model...\n",
            "Epoch : [9/200] | Step : [100/313] | Loss : 0.38717779517173767 \n",
            "Epoch : [9/200] | Step : [200/313] | Loss : 0.34470435976982117 \n",
            "Epoch : [9/200] | Step : [300/313] | Loss : 0.4755725562572479 \n",
            "Epoch : 9 | Loss : 0.4555852564093404 | Training Accuracy : 84.28763977635782% | Learning rate : 0.001\n",
            "Epoch 9 | Validation Accuracy 81.28955696202532%\n",
            "Saving the model...\n",
            "Epoch : [10/200] | Step : [100/313] | Loss : 0.32749995589256287 \n",
            "Epoch : [10/200] | Step : [200/313] | Loss : 0.4084102213382721 \n",
            "Epoch : [10/200] | Step : [300/313] | Loss : 0.40428221225738525 \n",
            "Epoch : 10 | Loss : 0.4134833392339012 | Training Accuracy : 85.6304912140575% | Learning rate : 0.001\n",
            "Epoch 10 | Validation Accuracy 82.89161392405063%\n",
            "Saving the model...\n",
            "Epoch : [11/200] | Step : [100/313] | Loss : 0.4418330490589142 \n",
            "Epoch : [11/200] | Step : [200/313] | Loss : 0.41322949528694153 \n",
            "Epoch : [11/200] | Step : [300/313] | Loss : 0.22348879277706146 \n",
            "Epoch : 11 | Loss : 0.38372508805399885 | Training Accuracy : 86.81609424920129% | Learning rate : 0.001\n",
            "Epoch 11 | Validation Accuracy 79.40071202531645%\n",
            "Epoch : [12/200] | Step : [100/313] | Loss : 0.37701043486595154 \n",
            "Epoch : [12/200] | Step : [200/313] | Loss : 0.40247678756713867 \n",
            "Epoch : [12/200] | Step : [300/313] | Loss : 0.24817372858524323 \n",
            "Epoch : 12 | Loss : 0.35458060018361187 | Training Accuracy : 87.72713658146965% | Learning rate : 0.001\n",
            "Epoch 12 | Validation Accuracy 84.52333860759494%\n",
            "Saving the model...\n",
            "Epoch : [13/200] | Step : [100/313] | Loss : 0.2202504277229309 \n",
            "Epoch : [13/200] | Step : [200/313] | Loss : 0.2594250738620758 \n",
            "Epoch : [13/200] | Step : [300/313] | Loss : 0.4715780019760132 \n",
            "Epoch : 13 | Loss : 0.3287543418308416 | Training Accuracy : 88.7030750798722% | Learning rate : 0.001\n",
            "Epoch 13 | Validation Accuracy 86.02650316455697%\n",
            "Saving the model...\n",
            "Epoch : [14/200] | Step : [100/313] | Loss : 0.48201024532318115 \n",
            "Epoch : [14/200] | Step : [200/313] | Loss : 0.3087032735347748 \n",
            "Epoch : [14/200] | Step : [300/313] | Loss : 0.2874601185321808 \n",
            "Epoch : 14 | Loss : 0.3011713438807204 | Training Accuracy : 89.51427715654951% | Learning rate : 0.001\n",
            "Epoch 14 | Validation Accuracy 83.08939873417721%\n",
            "Epoch : [15/200] | Step : [100/313] | Loss : 0.35218724608421326 \n",
            "Epoch : [15/200] | Step : [200/313] | Loss : 0.3060026168823242 \n",
            "Epoch : [15/200] | Step : [300/313] | Loss : 0.3064080476760864 \n",
            "Epoch : 15 | Loss : 0.28989658069115476 | Training Accuracy : 90.05591054313099% | Learning rate : 0.001\n",
            "Epoch 15 | Validation Accuracy 84.65189873417721%\n",
            "Epoch : [16/200] | Step : [100/313] | Loss : 0.301921010017395 \n",
            "Epoch : [16/200] | Step : [200/313] | Loss : 0.30142438411712646 \n",
            "Epoch : [16/200] | Step : [300/313] | Loss : 0.23368078470230103 \n",
            "Epoch : 16 | Loss : 0.2583312407945292 | Training Accuracy : 91.0792731629393% | Learning rate : 0.001\n",
            "Epoch 16 | Validation Accuracy 86.76819620253164%\n",
            "Saving the model...\n",
            "Epoch : [17/200] | Step : [100/313] | Loss : 0.18283838033676147 \n",
            "Epoch : [17/200] | Step : [200/313] | Loss : 0.2432788461446762 \n",
            "Epoch : [17/200] | Step : [300/313] | Loss : 0.27187496423721313 \n",
            "Epoch : 17 | Loss : 0.24343827488228156 | Training Accuracy : 91.50609025559106% | Learning rate : 0.001\n",
            "Epoch 17 | Validation Accuracy 85.77927215189874%\n",
            "Epoch : [18/200] | Step : [100/313] | Loss : 0.2236044853925705 \n",
            "Epoch : [18/200] | Step : [200/313] | Loss : 0.24092675745487213 \n",
            "Epoch : [18/200] | Step : [300/313] | Loss : 0.19269561767578125 \n",
            "Epoch : 18 | Loss : 0.22977317945835307 | Training Accuracy : 92.02525958466452% | Learning rate : 0.001\n",
            "Epoch 18 | Validation Accuracy 86.76819620253164%\n",
            "Epoch : [19/200] | Step : [100/313] | Loss : 0.18439918756484985 \n",
            "Epoch : [19/200] | Step : [200/313] | Loss : 0.2021179348230362 \n",
            "Epoch : [19/200] | Step : [300/313] | Loss : 0.4205608069896698 \n",
            "Epoch : 19 | Loss : 0.21469900333367217 | Training Accuracy : 92.50948482428115% | Learning rate : 0.001\n",
            "Epoch 19 | Validation Accuracy 87.95490506329115%\n",
            "Saving the model...\n",
            "Epoch : [20/200] | Step : [100/313] | Loss : 0.14350803196430206 \n",
            "Epoch : [20/200] | Step : [200/313] | Loss : 0.17117232084274292 \n",
            "Epoch : [20/200] | Step : [300/313] | Loss : 0.21743129193782806 \n",
            "Epoch : 20 | Loss : 0.20509239069569987 | Training Accuracy : 92.87889376996804% | Learning rate : 0.001\n",
            "Epoch 20 | Validation Accuracy 87.68789556962025%\n",
            "Epoch : [21/200] | Step : [100/313] | Loss : 0.2950045168399811 \n",
            "Epoch : [21/200] | Step : [200/313] | Loss : 0.2591232359409332 \n",
            "Epoch : [21/200] | Step : [300/313] | Loss : 0.1798163801431656 \n",
            "Epoch : 21 | Loss : 0.18536400076109 | Training Accuracy : 93.42801517571885% | Learning rate : 0.001\n",
            "Epoch 21 | Validation Accuracy 87.67800632911393%\n",
            "Epoch : [22/200] | Step : [100/313] | Loss : 0.15603061020374298 \n",
            "Epoch : [22/200] | Step : [200/313] | Loss : 0.1981498748064041 \n",
            "Epoch : [22/200] | Step : [300/313] | Loss : 0.1911073923110962 \n",
            "Epoch : 22 | Loss : 0.17897810238285566 | Training Accuracy : 93.71006389776358% | Learning rate : 0.001\n",
            "Epoch 22 | Validation Accuracy 88.39003164556962%\n",
            "Saving the model...\n",
            "Epoch : [23/200] | Step : [100/313] | Loss : 0.14639519155025482 \n",
            "Epoch : [23/200] | Step : [200/313] | Loss : 0.17668220400810242 \n",
            "Epoch : [23/200] | Step : [300/313] | Loss : 0.07994048297405243 \n",
            "Epoch : 23 | Loss : 0.16052631564890615 | Training Accuracy : 94.37899361022363% | Learning rate : 0.001\n",
            "Epoch 23 | Validation Accuracy 88.23180379746836%\n",
            "Epoch : [24/200] | Step : [100/313] | Loss : 0.17152540385723114 \n",
            "Epoch : [24/200] | Step : [200/313] | Loss : 0.17602913081645966 \n",
            "Epoch : [24/200] | Step : [300/313] | Loss : 0.2414577454328537 \n",
            "Epoch : 24 | Loss : 0.15222797453546297 | Training Accuracy : 94.74590654952077% | Learning rate : 0.001\n",
            "Epoch 24 | Validation Accuracy 88.74604430379746%\n",
            "Saving the model...\n",
            "Epoch : [25/200] | Step : [100/313] | Loss : 0.10617953538894653 \n",
            "Epoch : [25/200] | Step : [200/313] | Loss : 0.18003366887569427 \n",
            "Epoch : [25/200] | Step : [300/313] | Loss : 0.24418945610523224 \n",
            "Epoch : 25 | Loss : 0.14694957693997093 | Training Accuracy : 94.85073881789138% | Learning rate : 0.001\n",
            "Epoch 25 | Validation Accuracy 88.4493670886076%\n",
            "Epoch : [26/200] | Step : [100/313] | Loss : 0.11719585210084915 \n",
            "Epoch : [26/200] | Step : [200/313] | Loss : 0.21901001036167145 \n",
            "Epoch : [26/200] | Step : [300/313] | Loss : 0.13181814551353455 \n",
            "Epoch : 26 | Loss : 0.13964838777392055 | Training Accuracy : 95.06040335463258% | Learning rate : 0.001\n",
            "Epoch 26 | Validation Accuracy 89.56685126582279%\n",
            "Saving the model...\n",
            "Epoch : [27/200] | Step : [100/313] | Loss : 0.07396770268678665 \n",
            "Epoch : [27/200] | Step : [200/313] | Loss : 0.08616948872804642 \n",
            "Epoch : [27/200] | Step : [300/313] | Loss : 0.12152356654405594 \n",
            "Epoch : 27 | Loss : 0.12492108170074015 | Training Accuracy : 95.5770766773163% | Learning rate : 0.001\n",
            "Epoch 27 | Validation Accuracy 88.98338607594937%\n",
            "Epoch : [28/200] | Step : [100/313] | Loss : 0.058866675943136215 \n",
            "Epoch : [28/200] | Step : [200/313] | Loss : 0.2101261019706726 \n",
            "Epoch : [28/200] | Step : [300/313] | Loss : 0.12282131612300873 \n",
            "Epoch : 28 | Loss : 0.12372283924359102 | Training Accuracy : 95.48722044728434% | Learning rate : 0.001\n",
            "Epoch 28 | Validation Accuracy 88.05379746835443%\n",
            "Epoch : [29/200] | Step : [100/313] | Loss : 0.10276652872562408 \n",
            "Epoch : [29/200] | Step : [200/313] | Loss : 0.23678018152713776 \n",
            "Epoch : [29/200] | Step : [300/313] | Loss : 0.2537875771522522 \n",
            "Epoch : 29 | Loss : 0.11433632980686978 | Training Accuracy : 95.99390974440894% | Learning rate : 0.001\n",
            "Epoch 29 | Validation Accuracy 88.74604430379746%\n",
            "Epoch : [30/200] | Step : [100/313] | Loss : 0.08078031241893768 \n",
            "Epoch : [30/200] | Step : [200/313] | Loss : 0.04710621386766434 \n",
            "Epoch : [30/200] | Step : [300/313] | Loss : 0.1266583800315857 \n",
            "Epoch : 30 | Loss : 0.10420564414498905 | Training Accuracy : 96.30341453674122% | Learning rate : 0.001\n",
            "Epoch 30 | Validation Accuracy 88.5878164556962%\n",
            "Epoch : [31/200] | Step : [100/313] | Loss : 0.045623887330293655 \n",
            "Epoch : [31/200] | Step : [200/313] | Loss : 0.12997519969940186 \n",
            "Epoch : [31/200] | Step : [300/313] | Loss : 0.15972939133644104 \n",
            "Epoch : 31 | Loss : 0.11755775424619071 | Training Accuracy : 95.8716054313099% | Learning rate : 0.001\n",
            "Epoch 31 | Validation Accuracy 88.50870253164557%\n",
            "Epoch : [32/200] | Step : [100/313] | Loss : 0.053010065108537674 \n",
            "Epoch : [32/200] | Step : [200/313] | Loss : 0.07666437327861786 \n",
            "Epoch : [32/200] | Step : [300/313] | Loss : 0.10321169346570969 \n",
            "Epoch : 32 | Loss : 0.0992902185672674 | Training Accuracy : 96.47064696485623% | Learning rate : 0.001\n",
            "Epoch 32 | Validation Accuracy 89.61629746835443%\n",
            "Saving the model...\n",
            "Epoch : [33/200] | Step : [100/313] | Loss : 0.04863455519080162 \n",
            "Epoch : [33/200] | Step : [200/313] | Loss : 0.10270651429891586 \n",
            "Epoch : [33/200] | Step : [300/313] | Loss : 0.13603931665420532 \n",
            "Epoch : 33 | Loss : 0.08476241988638719 | Training Accuracy : 97.03224840255591% | Learning rate : 0.001\n",
            "Epoch 33 | Validation Accuracy 89.63607594936708%\n",
            "Saving the model...\n",
            "Epoch : [34/200] | Step : [100/313] | Loss : 0.07776380330324173 \n",
            "Epoch : [34/200] | Step : [200/313] | Loss : 0.0809604674577713 \n",
            "Epoch : [34/200] | Step : [300/313] | Loss : 0.15274280309677124 \n",
            "Epoch : 34 | Loss : 0.0876808226429902 | Training Accuracy : 96.87999201277955% | Learning rate : 0.001\n",
            "Epoch 34 | Validation Accuracy 88.8251582278481%\n",
            "Epoch : [35/200] | Step : [100/313] | Loss : 0.062236081808805466 \n",
            "Epoch : [35/200] | Step : [200/313] | Loss : 0.06260962784290314 \n",
            "Epoch : [35/200] | Step : [300/313] | Loss : 0.06971711665391922 \n",
            "Epoch : 35 | Loss : 0.08057988631113554 | Training Accuracy : 97.08216853035144% | Learning rate : 0.001\n",
            "Epoch 35 | Validation Accuracy 89.38884493670885%\n",
            "Epoch : [36/200] | Step : [100/313] | Loss : 0.1192709356546402 \n",
            "Epoch : [36/200] | Step : [200/313] | Loss : 0.08999312669038773 \n",
            "Epoch : [36/200] | Step : [300/313] | Loss : 0.11755486577749252 \n",
            "Epoch : 36 | Loss : 0.08236771487532712 | Training Accuracy : 97.05221645367412% | Learning rate : 0.001\n",
            "Epoch 36 | Validation Accuracy 89.95253164556962%\n",
            "Saving the model...\n",
            "Epoch : [37/200] | Step : [100/313] | Loss : 0.059097085148096085 \n",
            "Epoch : [37/200] | Step : [200/313] | Loss : 0.046031493693590164 \n",
            "Epoch : [37/200] | Step : [300/313] | Loss : 0.1906449943780899 \n",
            "Epoch : 37 | Loss : 0.09378061838114794 | Training Accuracy : 96.82757587859425% | Learning rate : 0.001\n",
            "Epoch 37 | Validation Accuracy 85.96716772151899%\n",
            "Epoch : [38/200] | Step : [100/313] | Loss : 0.09214837849140167 \n",
            "Epoch : [38/200] | Step : [200/313] | Loss : 0.0684254989027977 \n",
            "Epoch : [38/200] | Step : [300/313] | Loss : 0.07120831310749054 \n",
            "Epoch : 38 | Loss : 0.0919763089720005 | Training Accuracy : 96.8001198083067% | Learning rate : 0.001\n",
            "Epoch 38 | Validation Accuracy 90.0810917721519%\n",
            "Saving the model...\n",
            "Epoch : [39/200] | Step : [100/313] | Loss : 0.03478391095995903 \n",
            "Epoch : [39/200] | Step : [200/313] | Loss : 0.13099095225334167 \n",
            "Epoch : [39/200] | Step : [300/313] | Loss : 0.07555658370256424 \n",
            "Epoch : 39 | Loss : 0.06699783493357059 | Training Accuracy : 97.61880990415335% | Learning rate : 0.001\n",
            "Epoch 39 | Validation Accuracy 90.8623417721519%\n",
            "Saving the model...\n",
            "Epoch : [40/200] | Step : [100/313] | Loss : 0.06525253504514694 \n",
            "Epoch : [40/200] | Step : [200/313] | Loss : 0.031270477920770645 \n",
            "Epoch : [40/200] | Step : [300/313] | Loss : 0.061369847506284714 \n",
            "Epoch : 40 | Loss : 0.0595912852208502 | Training Accuracy : 97.9507787539936% | Learning rate : 0.001\n",
            "Epoch 40 | Validation Accuracy 90.70411392405063%\n",
            "Epoch : [41/200] | Step : [100/313] | Loss : 0.23568440973758698 \n",
            "Epoch : [41/200] | Step : [200/313] | Loss : 0.16299965977668762 \n",
            "Epoch : [41/200] | Step : [300/313] | Loss : 0.09918832033872604 \n",
            "Epoch : 41 | Loss : 0.060662008729724645 | Training Accuracy : 97.93330670926518% | Learning rate : 0.001\n",
            "Epoch 41 | Validation Accuracy 90.71400316455697%\n",
            "Epoch : [42/200] | Step : [100/313] | Loss : 0.021153489127755165 \n",
            "Epoch : [42/200] | Step : [200/313] | Loss : 0.04601305350661278 \n",
            "Epoch : [42/200] | Step : [300/313] | Loss : 0.045238789170980453 \n",
            "Epoch : 42 | Loss : 0.05608538267598413 | Training Accuracy : 98.09804313099042% | Learning rate : 0.001\n",
            "Epoch 42 | Validation Accuracy 89.98219936708861%\n",
            "Epoch : [43/200] | Step : [100/313] | Loss : 0.010307133197784424 \n",
            "Epoch : [43/200] | Step : [200/313] | Loss : 0.0437607616186142 \n",
            "Epoch : [43/200] | Step : [300/313] | Loss : 0.02710084617137909 \n",
            "Epoch : 43 | Loss : 0.057447243803225384 | Training Accuracy : 97.96575479233228% | Learning rate : 0.001\n",
            "Epoch 43 | Validation Accuracy 90.3184335443038%\n",
            "Epoch : [44/200] | Step : [100/313] | Loss : 0.08411651104688644 \n",
            "Epoch : [44/200] | Step : [200/313] | Loss : 0.05505998805165291 \n",
            "Epoch : [44/200] | Step : [300/313] | Loss : 0.05768362060189247 \n",
            "Epoch : 44 | Loss : 0.05148219187616017 | Training Accuracy : 98.2053714057508% | Learning rate : 0.001\n",
            "Epoch 44 | Validation Accuracy 89.99208860759494%\n",
            "Epoch : [45/200] | Step : [100/313] | Loss : 0.08531362563371658 \n",
            "Epoch : [45/200] | Step : [200/313] | Loss : 0.02777835540473461 \n",
            "Epoch : [45/200] | Step : [300/313] | Loss : 0.06543825566768646 \n",
            "Epoch : 45 | Loss : 0.05817219663036469 | Training Accuracy : 97.97823482428115% | Learning rate : 0.001\n",
            "Epoch 45 | Validation Accuracy 90.02175632911393%\n",
            "Epoch : [46/200] | Step : [100/313] | Loss : 0.13555283844470978 \n",
            "Epoch : [46/200] | Step : [200/313] | Loss : 0.02209065482020378 \n",
            "Epoch : [46/200] | Step : [300/313] | Loss : 0.047119393944740295 \n",
            "Epoch : 46 | Loss : 0.07797647462622188 | Training Accuracy : 97.34424920127796% | Learning rate : 0.001\n",
            "Epoch 46 | Validation Accuracy 90.2195411392405%\n",
            "Epoch : [47/200] | Step : [100/313] | Loss : 0.06750229001045227 \n",
            "Epoch : [47/200] | Step : [200/313] | Loss : 0.03927662596106529 \n",
            "Epoch : [47/200] | Step : [300/313] | Loss : 0.03930862620472908 \n",
            "Epoch : 47 | Loss : 0.05035618082069741 | Training Accuracy : 98.24530750798722% | Learning rate : 0.001\n",
            "Epoch 47 | Validation Accuracy 90.37776898734177%\n",
            "Epoch : [48/200] | Step : [100/313] | Loss : 0.0049652764573693275 \n",
            "Epoch : [48/200] | Step : [200/313] | Loss : 0.014019696041941643 \n",
            "Epoch : [48/200] | Step : [300/313] | Loss : 0.051943060010671616 \n",
            "Epoch : 48 | Loss : 0.043520359277796634 | Training Accuracy : 98.48242811501598% | Learning rate : 0.001\n",
            "Epoch 48 | Validation Accuracy 89.85363924050634%\n",
            "Epoch : [49/200] | Step : [100/313] | Loss : 0.0077661555260419846 \n",
            "Epoch : [49/200] | Step : [200/313] | Loss : 0.09892270714044571 \n",
            "Epoch : [49/200] | Step : [300/313] | Loss : 0.06291208416223526 \n",
            "Epoch : 49 | Loss : 0.04499756514776153 | Training Accuracy : 98.4050519169329% | Learning rate : 0.001\n",
            "Epoch 49 | Validation Accuracy 90.41732594936708%\n",
            "Epoch : [50/200] | Step : [100/313] | Loss : 0.06389237940311432 \n",
            "Epoch : [50/200] | Step : [200/313] | Loss : 0.022425487637519836 \n",
            "Epoch : [50/200] | Step : [300/313] | Loss : 0.05906642973423004 \n",
            "Epoch : 50 | Loss : 0.043791040743942175 | Training Accuracy : 98.45497204472844% | Learning rate : 0.001\n",
            "Epoch 50 | Validation Accuracy 90.96123417721519%\n",
            "Saving the model...\n",
            "Epoch : [51/200] | Step : [100/313] | Loss : 0.04178175702691078 \n",
            "Epoch : [51/200] | Step : [200/313] | Loss : 0.057927489280700684 \n",
            "Epoch : [51/200] | Step : [300/313] | Loss : 0.04047470539808273 \n",
            "Epoch : 51 | Loss : 0.04631505086690711 | Training Accuracy : 98.34015575079871% | Learning rate : 0.001\n",
            "Epoch 51 | Validation Accuracy 90.30854430379746%\n",
            "Epoch : [52/200] | Step : [100/313] | Loss : 0.09861238300800323 \n",
            "Epoch : [52/200] | Step : [200/313] | Loss : 0.023730764165520668 \n",
            "Epoch : [52/200] | Step : [300/313] | Loss : 0.09997843205928802 \n",
            "Epoch : 52 | Loss : 0.041185273970745076 | Training Accuracy : 98.61471645367412% | Learning rate : 0.001\n",
            "Epoch 52 | Validation Accuracy 91.02056962025317%\n",
            "Saving the model...\n",
            "Epoch : [53/200] | Step : [100/313] | Loss : 0.05228295922279358 \n",
            "Epoch : [53/200] | Step : [200/313] | Loss : 0.034592047333717346 \n",
            "Epoch : [53/200] | Step : [300/313] | Loss : 0.06700772792100906 \n",
            "Epoch : 53 | Loss : 0.04288626811169564 | Training Accuracy : 98.45746805111821% | Learning rate : 0.001\n",
            "Epoch 53 | Validation Accuracy 90.19976265822784%\n",
            "Epoch : [54/200] | Step : [100/313] | Loss : 0.01884051412343979 \n",
            "Epoch : [54/200] | Step : [200/313] | Loss : 0.04247138649225235 \n",
            "Epoch : [54/200] | Step : [300/313] | Loss : 0.08131783455610275 \n",
            "Epoch : 54 | Loss : 0.0427182393353849 | Training Accuracy : 98.52486022364218% | Learning rate : 0.001\n",
            "Epoch 54 | Validation Accuracy 90.84256329113924%\n",
            "Epoch : [55/200] | Step : [100/313] | Loss : 0.016940372064709663 \n",
            "Epoch : [55/200] | Step : [200/313] | Loss : 0.08962385356426239 \n",
            "Epoch : [55/200] | Step : [300/313] | Loss : 0.05847277119755745 \n",
            "Epoch : 55 | Loss : 0.038993651305471125 | Training Accuracy : 98.63718051118211% | Learning rate : 0.001\n",
            "Epoch 55 | Validation Accuracy 89.4382911392405%\n",
            "Epoch : [56/200] | Step : [100/313] | Loss : 0.01691376231610775 \n",
            "Epoch : [56/200] | Step : [200/313] | Loss : 0.04835011065006256 \n",
            "Epoch : [56/200] | Step : [300/313] | Loss : 0.04773382470011711 \n",
            "Epoch : 56 | Loss : 0.036447012970319236 | Training Accuracy : 98.78943690095848% | Learning rate : 0.001\n",
            "Epoch 56 | Validation Accuracy 91.1689082278481%\n",
            "Saving the model...\n",
            "Epoch : [57/200] | Step : [100/313] | Loss : 0.014451899565756321 \n",
            "Epoch : [57/200] | Step : [200/313] | Loss : 0.0037500113248825073 \n",
            "Epoch : [57/200] | Step : [300/313] | Loss : 0.04222753643989563 \n",
            "Epoch : 57 | Loss : 0.038329081364368765 | Training Accuracy : 98.69458865814697% | Learning rate : 0.001\n",
            "Epoch 57 | Validation Accuracy 91.02056962025317%\n",
            "Epoch : [58/200] | Step : [100/313] | Loss : 0.009901415556669235 \n",
            "Epoch : [58/200] | Step : [200/313] | Loss : 0.07532589137554169 \n",
            "Epoch : [58/200] | Step : [300/313] | Loss : 0.0467681847512722 \n",
            "Epoch : 58 | Loss : 0.03355146713105563 | Training Accuracy : 98.80441293929712% | Learning rate : 0.001\n",
            "Epoch 58 | Validation Accuracy 91.14912974683544%\n",
            "Epoch : [59/200] | Step : [100/313] | Loss : 0.10639956593513489 \n",
            "Epoch : [59/200] | Step : [200/313] | Loss : 0.006097323726862669 \n",
            "Epoch : [59/200] | Step : [300/313] | Loss : 0.047114256769418716 \n",
            "Epoch : 59 | Loss : 0.03636852938930293 | Training Accuracy : 98.71954872204472% | Learning rate : 0.001\n",
            "Epoch 59 | Validation Accuracy 90.49643987341773%\n",
            "Epoch : [60/200] | Step : [100/313] | Loss : 0.024264032021164894 \n",
            "Epoch : [60/200] | Step : [200/313] | Loss : 0.003844144521281123 \n",
            "Epoch : [60/200] | Step : [300/313] | Loss : 0.03194133937358856 \n",
            "Epoch : 60 | Loss : 0.03794964801776 | Training Accuracy : 98.73702076677317% | Learning rate : 0.001\n",
            "Epoch 60 | Validation Accuracy 90.77333860759494%\n",
            "Epoch : [61/200] | Step : [100/313] | Loss : 0.01633545756340027 \n",
            "Epoch : [61/200] | Step : [200/313] | Loss : 0.028206976130604744 \n",
            "Epoch : [61/200] | Step : [300/313] | Loss : 0.06095370650291443 \n",
            "Epoch : 61 | Loss : 0.03580099807906384 | Training Accuracy : 98.7744608626198% | Learning rate : 0.001\n",
            "Epoch 61 | Validation Accuracy 90.17009493670885%\n",
            "Epoch : [62/200] | Step : [100/313] | Loss : 0.028479229658842087 \n",
            "Epoch : [62/200] | Step : [200/313] | Loss : 0.025680020451545715 \n",
            "Epoch : [62/200] | Step : [300/313] | Loss : 0.09841903299093246 \n",
            "Epoch : 62 | Loss : 0.035351971333947615 | Training Accuracy : 98.74950079872204% | Learning rate : 0.001\n",
            "Epoch 62 | Validation Accuracy 91.17879746835443%\n",
            "Saving the model...\n",
            "Epoch : [63/200] | Step : [100/313] | Loss : 0.018243420869112015 \n",
            "Epoch : [63/200] | Step : [200/313] | Loss : 0.0648166686296463 \n",
            "Epoch : [63/200] | Step : [300/313] | Loss : 0.036143794655799866 \n",
            "Epoch : 63 | Loss : 0.03228694599749633 | Training Accuracy : 98.90425319488818% | Learning rate : 0.001\n",
            "Epoch 63 | Validation Accuracy 91.56447784810126%\n",
            "Saving the model...\n",
            "Epoch : [64/200] | Step : [100/313] | Loss : 0.018770545721054077 \n",
            "Epoch : [64/200] | Step : [200/313] | Loss : 0.005343233235180378 \n",
            "Epoch : [64/200] | Step : [300/313] | Loss : 0.052879054099321365 \n",
            "Epoch : 64 | Loss : 0.03156591074231762 | Training Accuracy : 98.93170926517571% | Learning rate : 0.001\n",
            "Epoch 64 | Validation Accuracy 90.80300632911393%\n",
            "Epoch : [65/200] | Step : [100/313] | Loss : 0.006788020487874746 \n",
            "Epoch : [65/200] | Step : [200/313] | Loss : 0.011195959523320198 \n",
            "Epoch : [65/200] | Step : [300/313] | Loss : 0.03642081841826439 \n",
            "Epoch : 65 | Loss : 0.030713403479199108 | Training Accuracy : 98.89426916932908% | Learning rate : 0.001\n",
            "Epoch 65 | Validation Accuracy 91.39636075949366%\n",
            "Epoch : [66/200] | Step : [100/313] | Loss : 0.1289755403995514 \n",
            "Epoch : [66/200] | Step : [200/313] | Loss : 0.05875655636191368 \n",
            "Epoch : [66/200] | Step : [300/313] | Loss : 0.040000803768634796 \n",
            "Epoch : 66 | Loss : 0.032800250342480256 | Training Accuracy : 98.90924520766772% | Learning rate : 0.001\n",
            "Epoch 66 | Validation Accuracy 90.91178797468355%\n",
            "Epoch : [67/200] | Step : [100/313] | Loss : 0.012089356780052185 \n",
            "Epoch : [67/200] | Step : [200/313] | Loss : 0.02710931934416294 \n",
            "Epoch : [67/200] | Step : [300/313] | Loss : 0.016791611909866333 \n",
            "Epoch : 67 | Loss : 0.02787572299703039 | Training Accuracy : 99.01407747603834% | Learning rate : 0.001\n",
            "Epoch 67 | Validation Accuracy 90.60522151898735%\n",
            "Epoch : [68/200] | Step : [100/313] | Loss : 0.028724998235702515 \n",
            "Epoch : [68/200] | Step : [200/313] | Loss : 0.10455647110939026 \n",
            "Epoch : [68/200] | Step : [300/313] | Loss : 0.012530467472970486 \n",
            "Epoch : 68 | Loss : 0.03231912661349764 | Training Accuracy : 98.85682907348243% | Learning rate : 0.001\n",
            "Epoch 68 | Validation Accuracy 90.70411392405063%\n",
            "Epoch : [69/200] | Step : [100/313] | Loss : 0.010159661993384361 \n",
            "Epoch : [69/200] | Step : [200/313] | Loss : 0.013258645310997963 \n",
            "Epoch : [69/200] | Step : [300/313] | Loss : 0.09042908996343613 \n",
            "Epoch : 69 | Loss : 0.03135682244378978 | Training Accuracy : 98.97663738019169% | Learning rate : 0.001\n",
            "Epoch 69 | Validation Accuracy 90.43710443037975%\n",
            "Epoch : [70/200] | Step : [100/313] | Loss : 0.020862700417637825 \n",
            "Epoch : [70/200] | Step : [200/313] | Loss : 0.020735062658786774 \n",
            "Epoch : [70/200] | Step : [300/313] | Loss : 0.034213945269584656 \n",
            "Epoch : 70 | Loss : 0.02556727008712582 | Training Accuracy : 99.17132587859425% | Learning rate : 0.001\n",
            "Epoch 70 | Validation Accuracy 90.80300632911393%\n",
            "Epoch : [71/200] | Step : [100/313] | Loss : 0.04617241397500038 \n",
            "Epoch : [71/200] | Step : [200/313] | Loss : 0.0061986250802874565 \n",
            "Epoch : [71/200] | Step : [300/313] | Loss : 0.002422669669613242 \n",
            "Epoch : 71 | Loss : 0.03071082764105818 | Training Accuracy : 98.98911741214057% | Learning rate : 0.001\n",
            "Epoch 71 | Validation Accuracy 90.39754746835443%\n",
            "Epoch : [72/200] | Step : [100/313] | Loss : 0.007147719152271748 \n",
            "Epoch : [72/200] | Step : [200/313] | Loss : 0.014347263611853123 \n",
            "Epoch : [72/200] | Step : [300/313] | Loss : 0.05606274679303169 \n",
            "Epoch : 72 | Loss : 0.0263408737594839 | Training Accuracy : 99.03404552715655% | Learning rate : 0.001\n",
            "Epoch 72 | Validation Accuracy 90.44699367088607%\n",
            "Epoch : [73/200] | Step : [100/313] | Loss : 0.02082969807088375 \n",
            "Epoch : [73/200] | Step : [200/313] | Loss : 0.074018694460392 \n",
            "Epoch : [73/200] | Step : [300/313] | Loss : 0.018707601353526115 \n",
            "Epoch : 73 | Loss : 0.02901992153714057 | Training Accuracy : 99.029053514377% | Learning rate : 0.001\n",
            "Epoch 73 | Validation Accuracy 90.94145569620254%\n",
            "Epoch : [74/200] | Step : [100/313] | Loss : 0.02818642184138298 \n",
            "Epoch : [74/200] | Step : [200/313] | Loss : 0.03245363384485245 \n",
            "Epoch : [74/200] | Step : [300/313] | Loss : 0.04757912456989288 \n",
            "Epoch : 74 | Loss : 0.02413233774252974 | Training Accuracy : 99.19628594249201% | Learning rate : 0.001\n",
            "Epoch 74 | Validation Accuracy 91.41613924050634%\n",
            "Epoch : [75/200] | Step : [100/313] | Loss : 0.1521119326353073 \n",
            "Epoch : [75/200] | Step : [200/313] | Loss : 0.012319648638367653 \n",
            "Epoch : [75/200] | Step : [300/313] | Loss : 0.061681341379880905 \n",
            "Epoch : 75 | Loss : 0.04010678694535868 | Training Accuracy : 98.7120607028754% | Learning rate : 0.001\n",
            "Epoch 75 | Validation Accuracy 91.44580696202532%\n",
            "Epoch : [76/200] | Step : [100/313] | Loss : 0.01683557964861393 \n",
            "Epoch : [76/200] | Step : [200/313] | Loss : 0.004955195356160402 \n",
            "Epoch : [76/200] | Step : [300/313] | Loss : 0.07059531658887863 \n",
            "Epoch : 76 | Loss : 0.023799723939607127 | Training Accuracy : 99.21875% | Learning rate : 0.001\n",
            "Epoch 76 | Validation Accuracy 90.96123417721519%\n",
            "Epoch : [77/200] | Step : [100/313] | Loss : 0.056797292083501816 \n",
            "Epoch : [77/200] | Step : [200/313] | Loss : 0.06879188120365143 \n",
            "Epoch : [77/200] | Step : [300/313] | Loss : 0.026178080588579178 \n",
            "Epoch : 77 | Loss : 0.026090908291252754 | Training Accuracy : 99.1039337060703% | Learning rate : 0.001\n",
            "Epoch 77 | Validation Accuracy 91.19857594936708%\n",
            "Epoch : [78/200] | Step : [100/313] | Loss : 0.004935953300446272 \n",
            "Epoch : [78/200] | Step : [200/313] | Loss : 0.010035564191639423 \n",
            "Epoch : [78/200] | Step : [300/313] | Loss : 0.0411682054400444 \n",
            "Epoch : 78 | Loss : 0.025755144081438502 | Training Accuracy : 99.11142172523961% | Learning rate : 0.001\n",
            "Epoch 78 | Validation Accuracy 90.58544303797468%\n",
            "Epoch : [79/200] | Step : [100/313] | Loss : 0.03637422248721123 \n",
            "Epoch : [79/200] | Step : [200/313] | Loss : 0.0040748706087470055 \n",
            "Epoch : [79/200] | Step : [300/313] | Loss : 0.005118352361023426 \n",
            "Epoch : 79 | Loss : 0.023376462240770352 | Training Accuracy : 99.20626996805112% | Learning rate : 0.001\n",
            "Epoch 79 | Validation Accuracy 91.21835443037975%\n",
            "Epoch : [80/200] | Step : [100/313] | Loss : 0.0054585919715464115 \n",
            "Epoch : [80/200] | Step : [200/313] | Loss : 0.00609587924554944 \n",
            "Epoch : [80/200] | Step : [300/313] | Loss : 0.02605503238737583 \n",
            "Epoch : 80 | Loss : 0.02197802634262584 | Training Accuracy : 99.25369408945687% | Learning rate : 0.001\n",
            "Epoch 80 | Validation Accuracy 91.39636075949366%\n",
            "Epoch : [81/200] | Step : [100/313] | Loss : 0.003173666540533304 \n",
            "Epoch : [81/200] | Step : [200/313] | Loss : 0.025747142732143402 \n",
            "Epoch : [81/200] | Step : [300/313] | Loss : 0.009692927822470665 \n",
            "Epoch : 81 | Loss : 0.019559635631885147 | Training Accuracy : 99.35852635782749% | Learning rate : 0.001\n",
            "Epoch 81 | Validation Accuracy 91.27768987341773%\n",
            "Epoch : [82/200] | Step : [100/313] | Loss : 0.053167443722486496 \n",
            "Epoch : [82/200] | Step : [200/313] | Loss : 0.039518680423498154 \n",
            "Epoch : [82/200] | Step : [300/313] | Loss : 0.04125697910785675 \n",
            "Epoch : 82 | Loss : 0.02765137264311623 | Training Accuracy : 99.04652555910543% | Learning rate : 0.001\n",
            "Epoch 82 | Validation Accuracy 91.29746835443038%\n",
            "Epoch : [83/200] | Step : [100/313] | Loss : 0.06492873281240463 \n",
            "Epoch : [83/200] | Step : [200/313] | Loss : 0.018403900787234306 \n",
            "Epoch : [83/200] | Step : [300/313] | Loss : 0.002099588280543685 \n",
            "Epoch : 83 | Loss : 0.03933680013749011 | Training Accuracy : 98.67711661341852% | Learning rate : 0.001\n",
            "Epoch 83 | Validation Accuracy 91.18868670886076%\n",
            "Epoch : [84/200] | Step : [100/313] | Loss : 0.1392051726579666 \n",
            "Epoch : [84/200] | Step : [200/313] | Loss : 0.02364107221364975 \n",
            "Epoch : [84/200] | Step : [300/313] | Loss : 0.024480024352669716 \n",
            "Epoch : 84 | Loss : 0.0326767590022631 | Training Accuracy : 98.9342052715655% | Learning rate : 0.001\n",
            "Epoch 84 | Validation Accuracy 91.31724683544303%\n",
            "Epoch : [85/200] | Step : [100/313] | Loss : 0.0017045519780367613 \n",
            "Epoch : [85/200] | Step : [200/313] | Loss : 0.06474187225103378 \n",
            "Epoch : [85/200] | Step : [300/313] | Loss : 0.0849873498082161 \n",
            "Epoch : 85 | Loss : 0.042318258823205036 | Training Accuracy : 98.60473242811501% | Learning rate : 0.001\n",
            "Epoch 85 | Validation Accuracy 90.81289556962025%\n",
            "Epoch : [86/200] | Step : [100/313] | Loss : 0.007930670864880085 \n",
            "Epoch : [86/200] | Step : [200/313] | Loss : 0.002924793167039752 \n",
            "Epoch : [86/200] | Step : [300/313] | Loss : 0.015710756182670593 \n",
            "Epoch : 86 | Loss : 0.019650842502382925 | Training Accuracy : 99.3560303514377% | Learning rate : 0.001\n",
            "Epoch 86 | Validation Accuracy 92.00949367088607%\n",
            "Saving the model...\n",
            "Epoch : [87/200] | Step : [100/313] | Loss : 0.013289326801896095 \n",
            "Epoch : [87/200] | Step : [200/313] | Loss : 0.007706253789365292 \n",
            "Epoch : [87/200] | Step : [300/313] | Loss : 0.029359908774495125 \n",
            "Epoch : 87 | Loss : 0.012427651876908766 | Training Accuracy : 99.53324680511182% | Learning rate : 0.001\n",
            "Epoch 87 | Validation Accuracy 91.62381329113924%\n",
            "Epoch : [88/200] | Step : [100/313] | Loss : 0.012607607990503311 \n",
            "Epoch : [88/200] | Step : [200/313] | Loss : 0.017943743616342545 \n",
            "Epoch : [88/200] | Step : [300/313] | Loss : 0.045007046312093735 \n",
            "Epoch : 88 | Loss : 0.017198965696732516 | Training Accuracy : 99.40095846645367% | Learning rate : 0.001\n",
            "Epoch 88 | Validation Accuracy 91.0007911392405%\n",
            "Epoch : [89/200] | Step : [100/313] | Loss : 0.0150351133197546 \n",
            "Epoch : [89/200] | Step : [200/313] | Loss : 0.03037191927433014 \n",
            "Epoch : [89/200] | Step : [300/313] | Loss : 0.030089078471064568 \n",
            "Epoch : 89 | Loss : 0.019817716419825496 | Training Accuracy : 99.30611022364218% | Learning rate : 0.001\n",
            "Epoch 89 | Validation Accuracy 91.34691455696202%\n",
            "Epoch : [90/200] | Step : [100/313] | Loss : 0.005842758808284998 \n",
            "Epoch : [90/200] | Step : [200/313] | Loss : 0.03175067901611328 \n",
            "Epoch : [90/200] | Step : [300/313] | Loss : 0.007638466544449329 \n",
            "Epoch : 90 | Loss : 0.016091106613758004 | Training Accuracy : 99.41593450479233% | Learning rate : 0.001\n",
            "Epoch 90 | Validation Accuracy 91.66337025316456%\n",
            "Epoch : [91/200] | Step : [100/313] | Loss : 0.01549435406923294 \n",
            "Epoch : [91/200] | Step : [200/313] | Loss : 0.006092289462685585 \n",
            "Epoch : [91/200] | Step : [300/313] | Loss : 0.011382773518562317 \n",
            "Epoch : 91 | Loss : 0.022265131609754626 | Training Accuracy : 99.24620607028754% | Learning rate : 0.001\n",
            "Epoch 91 | Validation Accuracy 91.17879746835443%\n",
            "Epoch : [92/200] | Step : [100/313] | Loss : 0.0007705749594606459 \n",
            "Epoch : [92/200] | Step : [200/313] | Loss : 0.0040439716540277 \n",
            "Epoch : [92/200] | Step : [300/313] | Loss : 0.01810504123568535 \n",
            "Epoch : 92 | Loss : 0.019609648592717285 | Training Accuracy : 99.35103833865814% | Learning rate : 0.001\n",
            "Epoch 92 | Validation Accuracy 91.06012658227847%\n",
            "Epoch : [93/200] | Step : [100/313] | Loss : 0.004265842493623495 \n",
            "Epoch : [93/200] | Step : [200/313] | Loss : 0.049977898597717285 \n",
            "Epoch : [93/200] | Step : [300/313] | Loss : 0.010889794677495956 \n",
            "Epoch : 93 | Loss : 0.020831634277963605 | Training Accuracy : 99.23372603833866% | Learning rate : 0.001\n",
            "Epoch 93 | Validation Accuracy 90.67444620253164%\n",
            "Epoch : [94/200] | Step : [100/313] | Loss : 0.007394710090011358 \n",
            "Epoch : [94/200] | Step : [200/313] | Loss : 0.005739226005971432 \n",
            "Epoch : [94/200] | Step : [300/313] | Loss : 0.03484862670302391 \n",
            "Epoch : 94 | Loss : 0.022183050532801486 | Training Accuracy : 99.26867012779552% | Learning rate : 0.001\n",
            "Epoch 94 | Validation Accuracy 90.6942246835443%\n",
            "Epoch : [95/200] | Step : [100/313] | Loss : 0.02410283125936985 \n",
            "Epoch : [95/200] | Step : [200/313] | Loss : 0.013927020132541656 \n",
            "Epoch : [95/200] | Step : [300/313] | Loss : 0.024022623896598816 \n",
            "Epoch : 95 | Loss : 0.019445173796630813 | Training Accuracy : 99.3360623003195% | Learning rate : 0.001\n",
            "Epoch 95 | Validation Accuracy 90.98101265822784%\n",
            "Epoch : [96/200] | Step : [100/313] | Loss : 0.03816632181406021 \n",
            "Epoch : [96/200] | Step : [200/313] | Loss : 0.01083097979426384 \n",
            "Epoch : [96/200] | Step : [300/313] | Loss : 0.007381016854196787 \n",
            "Epoch : 96 | Loss : 0.0173011235361837 | Training Accuracy : 99.41593450479233% | Learning rate : 0.001\n",
            "Epoch 96 | Validation Accuracy 91.05023734177216%\n",
            "Epoch : [97/200] | Step : [100/313] | Loss : 0.00795402005314827 \n",
            "Epoch : [97/200] | Step : [200/313] | Loss : 0.009149700403213501 \n",
            "Epoch : [97/200] | Step : [300/313] | Loss : 0.0860397219657898 \n",
            "Epoch : 97 | Loss : 0.018895263341125308 | Training Accuracy : 99.36102236421725% | Learning rate : 0.001\n",
            "Epoch 97 | Validation Accuracy 91.27768987341773%\n",
            "Epoch : [98/200] | Step : [100/313] | Loss : 0.003816302167251706 \n",
            "Epoch : [98/200] | Step : [200/313] | Loss : 0.013768577016890049 \n",
            "Epoch : [98/200] | Step : [300/313] | Loss : 0.0018116390565410256 \n",
            "Epoch : 98 | Loss : 0.018173578082019994 | Training Accuracy : 99.37350239616613% | Learning rate : 0.001\n",
            "Epoch 98 | Validation Accuracy 91.65348101265823%\n",
            "Epoch : [99/200] | Step : [100/313] | Loss : 0.035242125391960144 \n",
            "Epoch : [99/200] | Step : [200/313] | Loss : 0.021771913394331932 \n",
            "Epoch : [99/200] | Step : [300/313] | Loss : 0.002364933490753174 \n",
            "Epoch : 99 | Loss : 0.01979381938523705 | Training Accuracy : 99.36102236421725% | Learning rate : 0.001\n",
            "Epoch 99 | Validation Accuracy 91.44580696202532%\n",
            "Epoch : [100/200] | Step : [100/313] | Loss : 0.0018556934082880616 \n",
            "Epoch : [100/200] | Step : [200/313] | Loss : 0.018543235957622528 \n",
            "Epoch : [100/200] | Step : [300/313] | Loss : 0.02217276021838188 \n",
            "Epoch : 100 | Loss : 0.017960457848169256 | Training Accuracy : 99.36851038338658% | Learning rate : 0.001\n",
            "Epoch 100 | Validation Accuracy 91.76226265822784%\n",
            "Epoch : [101/200] | Step : [100/313] | Loss : 0.014761243015527725 \n",
            "Epoch : [101/200] | Step : [200/313] | Loss : 0.012072906829416752 \n",
            "Epoch : [101/200] | Step : [300/313] | Loss : 0.023010503500699997 \n",
            "Epoch : 101 | Loss : 0.01852343004564539 | Training Accuracy : 99.39097444089457% | Learning rate : 0.001\n",
            "Epoch 101 | Validation Accuracy 91.66337025316456%\n",
            "Epoch : [102/200] | Step : [100/313] | Loss : 0.028960369527339935 \n",
            "Epoch : [102/200] | Step : [200/313] | Loss : 0.026308337226510048 \n",
            "Epoch : [102/200] | Step : [300/313] | Loss : 0.0007513161399401724 \n",
            "Epoch : 102 | Loss : 0.016943768012343336 | Training Accuracy : 99.44838258785943% | Learning rate : 0.001\n",
            "Epoch 102 | Validation Accuracy 91.90071202531645%\n",
            "Epoch : [103/200] | Step : [100/313] | Loss : 0.0019465731456875801 \n",
            "Epoch : [103/200] | Step : [200/313] | Loss : 0.0270454790443182 \n",
            "Epoch : [103/200] | Step : [300/313] | Loss : 0.02201947756111622 \n",
            "Epoch : 103 | Loss : 0.01752389822819697 | Training Accuracy : 99.43340654952077% | Learning rate : 0.001\n",
            "Epoch 103 | Validation Accuracy 91.06012658227847%\n",
            "Epoch : [104/200] | Step : [100/313] | Loss : 0.009838425554335117 \n",
            "Epoch : [104/200] | Step : [200/313] | Loss : 0.026095956563949585 \n",
            "Epoch : [104/200] | Step : [300/313] | Loss : 0.008440680801868439 \n",
            "Epoch : 104 | Loss : 0.021088237144940417 | Training Accuracy : 99.33107028753993% | Learning rate : 0.001\n",
            "Epoch 104 | Validation Accuracy 91.13924050632912%\n",
            "Epoch : [105/200] | Step : [100/313] | Loss : 0.023922014981508255 \n",
            "Epoch : [105/200] | Step : [200/313] | Loss : 0.020472826436161995 \n",
            "Epoch : [105/200] | Step : [300/313] | Loss : 0.006864944007247686 \n",
            "Epoch : 105 | Loss : 0.017319097470870754 | Training Accuracy : 99.44838258785943% | Learning rate : 0.001\n",
            "Epoch 105 | Validation Accuracy 91.39636075949366%\n",
            "Epoch : [106/200] | Step : [100/313] | Loss : 0.0048341830261051655 \n",
            "Epoch : [106/200] | Step : [200/313] | Loss : 0.00987912155687809 \n",
            "Epoch : [106/200] | Step : [300/313] | Loss : 0.015796633437275887 \n",
            "Epoch : 106 | Loss : 0.015514970385226251 | Training Accuracy : 99.5032947284345% | Learning rate : 0.001\n",
            "Epoch 106 | Validation Accuracy 91.32713607594937%\n",
            "Epoch : [107/200] | Step : [100/313] | Loss : 0.010041570290923119 \n",
            "Epoch : [107/200] | Step : [200/313] | Loss : 0.001259476994164288 \n",
            "Epoch : [107/200] | Step : [300/313] | Loss : 0.006948279216885567 \n",
            "Epoch : 107 | Loss : 0.014759129448775232 | Training Accuracy : 99.54323083067092% | Learning rate : 0.001\n",
            "Epoch 107 | Validation Accuracy 91.29746835443038%\n",
            "Epoch : [108/200] | Step : [100/313] | Loss : 0.05797682702541351 \n",
            "Epoch : [108/200] | Step : [200/313] | Loss : 0.021253544837236404 \n",
            "Epoch : [108/200] | Step : [300/313] | Loss : 0.013524935580790043 \n",
            "Epoch : 108 | Loss : 0.0186410781470114 | Training Accuracy : 99.33107028753993% | Learning rate : 0.001\n",
            "Epoch 108 | Validation Accuracy 91.67325949367088%\n",
            "Epoch : [109/200] | Step : [100/313] | Loss : 0.0025617622304707766 \n",
            "Epoch : [109/200] | Step : [200/313] | Loss : 0.016057806089520454 \n",
            "Epoch : [109/200] | Step : [300/313] | Loss : 0.00782780908048153 \n",
            "Epoch : 109 | Loss : 0.015484033444708141 | Training Accuracy : 99.48083067092651% | Learning rate : 0.001\n",
            "Epoch 109 | Validation Accuracy 91.7820411392405%\n",
            "Epoch : [110/200] | Step : [100/313] | Loss : 0.010945622809231281 \n",
            "Epoch : [110/200] | Step : [200/313] | Loss : 0.008662302978336811 \n",
            "Epoch : [110/200] | Step : [300/313] | Loss : 0.02986862324178219 \n",
            "Epoch : 110 | Loss : 0.013872744811969562 | Training Accuracy : 99.4933107028754% | Learning rate : 0.001\n",
            "Epoch 110 | Validation Accuracy 91.07990506329115%\n",
            "Epoch : [111/200] | Step : [100/313] | Loss : 0.0013641070108860731 \n",
            "Epoch : [111/200] | Step : [200/313] | Loss : 0.0003568357788026333 \n",
            "Epoch : [111/200] | Step : [300/313] | Loss : 0.0020820903591811657 \n",
            "Epoch : 111 | Loss : 0.01937720739411357 | Training Accuracy : 99.36851038338658% | Learning rate : 0.001\n",
            "Epoch 111 | Validation Accuracy 91.58425632911393%\n",
            "Epoch : [112/200] | Step : [100/313] | Loss : 0.006882300600409508 \n",
            "Epoch : [112/200] | Step : [200/313] | Loss : 0.005032933317124844 \n",
            "Epoch : [112/200] | Step : [300/313] | Loss : 0.009268990717828274 \n",
            "Epoch : 112 | Loss : 0.013464430391252153 | Training Accuracy : 99.55071884984025% | Learning rate : 0.001\n",
            "Epoch 112 | Validation Accuracy 91.97982594936708%\n",
            "Epoch : [113/200] | Step : [100/313] | Loss : 0.0037270921748131514 \n",
            "Epoch : [113/200] | Step : [200/313] | Loss : 0.002936250763013959 \n",
            "Epoch : [113/200] | Step : [300/313] | Loss : 0.00023825584503356367 \n",
            "Epoch : 113 | Loss : 0.009868026554137066 | Training Accuracy : 99.65555111821087% | Learning rate : 0.001\n",
            "Epoch 113 | Validation Accuracy 90.85245253164557%\n",
            "Epoch : [114/200] | Step : [100/313] | Loss : 0.007157912943512201 \n",
            "Epoch : [114/200] | Step : [200/313] | Loss : 0.05898910015821457 \n",
            "Epoch : [114/200] | Step : [300/313] | Loss : 0.015454516746103764 \n",
            "Epoch : 114 | Loss : 0.02102745530136397 | Training Accuracy : 99.29612619808307% | Learning rate : 0.001\n",
            "Epoch 114 | Validation Accuracy 91.27768987341773%\n",
            "Epoch : [115/200] | Step : [100/313] | Loss : 0.02108890935778618 \n",
            "Epoch : [115/200] | Step : [200/313] | Loss : 0.0014541876735165715 \n",
            "Epoch : [115/200] | Step : [300/313] | Loss : 0.008344638161361217 \n",
            "Epoch : 115 | Loss : 0.01635848685184839 | Training Accuracy : 99.45587060702876% | Learning rate : 0.001\n",
            "Epoch 115 | Validation Accuracy 91.61392405063292%\n",
            "Epoch : [116/200] | Step : [100/313] | Loss : 0.0019865790382027626 \n",
            "Epoch : [116/200] | Step : [200/313] | Loss : 0.0029916451312601566 \n",
            "Epoch : [116/200] | Step : [300/313] | Loss : 0.00869716051965952 \n",
            "Epoch : 116 | Loss : 0.015746933982347527 | Training Accuracy : 99.48831869009584% | Learning rate : 0.001\n",
            "Epoch 116 | Validation Accuracy 91.63370253164557%\n",
            "Epoch : [117/200] | Step : [100/313] | Loss : 0.027156969532370567 \n",
            "Epoch : [117/200] | Step : [200/313] | Loss : 0.0019574612379074097 \n",
            "Epoch : [117/200] | Step : [300/313] | Loss : 0.04685090854763985 \n",
            "Epoch : 117 | Loss : 0.014940601612326685 | Training Accuracy : 99.5032947284345% | Learning rate : 0.001\n",
            "Epoch 117 | Validation Accuracy 90.83267405063292%\n",
            "Epoch : [118/200] | Step : [100/313] | Loss : 0.0023736509028822184 \n",
            "Epoch : [118/200] | Step : [200/313] | Loss : 0.019983971491456032 \n",
            "Epoch : [118/200] | Step : [300/313] | Loss : 0.011300270445644855 \n",
            "Epoch : 118 | Loss : 0.014655863472052996 | Training Accuracy : 99.53324680511182% | Learning rate : 0.001\n",
            "Epoch 118 | Validation Accuracy 92.34572784810126%\n",
            "Saving the model...\n",
            "Epoch : [119/200] | Step : [100/313] | Loss : 0.006424794439226389 \n",
            "Epoch : [119/200] | Step : [200/313] | Loss : 0.014527150429785252 \n",
            "Epoch : [119/200] | Step : [300/313] | Loss : 0.0018794054631143808 \n",
            "Epoch : 119 | Loss : 0.013510183400988501 | Training Accuracy : 99.54822284345049% | Learning rate : 0.001\n",
            "Epoch 119 | Validation Accuracy 91.39636075949366%\n",
            "Epoch : [120/200] | Step : [100/313] | Loss : 0.005517612211406231 \n",
            "Epoch : [120/200] | Step : [200/313] | Loss : 0.00384694105014205 \n",
            "Epoch : [120/200] | Step : [300/313] | Loss : 0.0010448491666465998 \n",
            "Epoch : 120 | Loss : 0.014271257751178332 | Training Accuracy : 99.5157747603834% | Learning rate : 0.001\n",
            "Epoch 120 | Validation Accuracy 91.8809335443038%\n",
            "Epoch : [121/200] | Step : [100/313] | Loss : 0.06817075610160828 \n",
            "Epoch : [121/200] | Step : [200/313] | Loss : 0.0022974517196416855 \n",
            "Epoch : [121/200] | Step : [300/313] | Loss : 0.010450427420437336 \n",
            "Epoch : 121 | Loss : 0.012133662310362342 | Training Accuracy : 99.59315095846645% | Learning rate : 0.001\n",
            "Epoch 121 | Validation Accuracy 91.50514240506328%\n",
            "Epoch : [122/200] | Step : [100/313] | Loss : 0.016606340184807777 \n",
            "Epoch : [122/200] | Step : [200/313] | Loss : 0.021053241565823555 \n",
            "Epoch : [122/200] | Step : [300/313] | Loss : 0.010491099208593369 \n",
            "Epoch : 122 | Loss : 0.015468215548374598 | Training Accuracy : 99.46335862619809% | Learning rate : 0.001\n",
            "Epoch 122 | Validation Accuracy 91.1689082278481%\n",
            "Epoch : [123/200] | Step : [100/313] | Loss : 0.029746273532509804 \n",
            "Epoch : [123/200] | Step : [200/313] | Loss : 0.059881605207920074 \n",
            "Epoch : [123/200] | Step : [300/313] | Loss : 0.03054642491042614 \n",
            "Epoch : 123 | Loss : 0.013924858749543982 | Training Accuracy : 99.50828674121406% | Learning rate : 0.001\n",
            "Epoch 123 | Validation Accuracy 90.96123417721519%\n",
            "Epoch : [124/200] | Step : [100/313] | Loss : 0.04229016602039337 \n",
            "Epoch : [124/200] | Step : [200/313] | Loss : 0.025837766006588936 \n",
            "Epoch : [124/200] | Step : [300/313] | Loss : 0.003410337259992957 \n",
            "Epoch : 124 | Loss : 0.015296275054854817 | Training Accuracy : 99.47084664536742% | Learning rate : 0.001\n",
            "Epoch 124 | Validation Accuracy 91.0996835443038%\n",
            "Epoch : [125/200] | Step : [100/313] | Loss : 0.0738033726811409 \n",
            "Epoch : [125/200] | Step : [200/313] | Loss : 0.01308183278888464 \n",
            "Epoch : [125/200] | Step : [300/313] | Loss : 0.016027918085455894 \n",
            "Epoch : 125 | Loss : 0.017213705478023332 | Training Accuracy : 99.38598242811501% | Learning rate : 0.001\n",
            "Epoch 125 | Validation Accuracy 91.31724683544303%\n",
            "Epoch : [126/200] | Step : [100/313] | Loss : 0.0032223323360085487 \n",
            "Epoch : [126/200] | Step : [200/313] | Loss : 0.020902469754219055 \n",
            "Epoch : [126/200] | Step : [300/313] | Loss : 0.008434269577264786 \n",
            "Epoch : 126 | Loss : 0.010715972481861923 | Training Accuracy : 99.62559904153355% | Learning rate : 0.001\n",
            "Epoch 126 | Validation Accuracy 91.91060126582279%\n",
            "Epoch : [127/200] | Step : [100/313] | Loss : 0.012052114121615887 \n",
            "Epoch : [127/200] | Step : [200/313] | Loss : 0.006856108084321022 \n",
            "Epoch : [127/200] | Step : [300/313] | Loss : 0.0026551373302936554 \n",
            "Epoch : 127 | Loss : 0.015123871465764245 | Training Accuracy : 99.51078274760383% | Learning rate : 0.001\n",
            "Epoch 127 | Validation Accuracy 90.88212025316456%\n",
            "Epoch : [128/200] | Step : [100/313] | Loss : 0.028940092772245407 \n",
            "Epoch : [128/200] | Step : [200/313] | Loss : 0.004039142280817032 \n",
            "Epoch : [128/200] | Step : [300/313] | Loss : 0.0044455816969275475 \n",
            "Epoch : 128 | Loss : 0.014497386909405382 | Training Accuracy : 99.49830271565496% | Learning rate : 0.001\n",
            "Epoch 128 | Validation Accuracy 91.4754746835443%\n",
            "Epoch : [129/200] | Step : [100/313] | Loss : 0.07694859802722931 \n",
            "Epoch : [129/200] | Step : [200/313] | Loss : 0.00585956871509552 \n",
            "Epoch : [129/200] | Step : [300/313] | Loss : 0.05009230598807335 \n",
            "Epoch : 129 | Loss : 0.012812708465165992 | Training Accuracy : 99.59065495207668% | Learning rate : 0.001\n",
            "Epoch 129 | Validation Accuracy 90.97112341772153%\n",
            "Epoch : [130/200] | Step : [100/313] | Loss : 0.020835502073168755 \n",
            "Epoch : [130/200] | Step : [200/313] | Loss : 0.018871653825044632 \n",
            "Epoch : [130/200] | Step : [300/313] | Loss : 0.001392885809764266 \n",
            "Epoch : 130 | Loss : 0.014486573996284929 | Training Accuracy : 99.4508785942492% | Learning rate : 0.001\n",
            "Epoch 130 | Validation Accuracy 92.08860759493672%\n",
            "Epoch : [131/200] | Step : [100/313] | Loss : 0.005352018866688013 \n",
            "Epoch : [131/200] | Step : [200/313] | Loss : 0.011352626606822014 \n",
            "Epoch : [131/200] | Step : [300/313] | Loss : 0.004256779327988625 \n",
            "Epoch : 131 | Loss : 0.013384033930015575 | Training Accuracy : 99.54822284345049% | Learning rate : 0.001\n",
            "Epoch 131 | Validation Accuracy 91.22824367088607%\n",
            "Epoch : [132/200] | Step : [100/313] | Loss : 0.003189469687640667 \n",
            "Epoch : [132/200] | Step : [200/313] | Loss : 0.0207036305218935 \n",
            "Epoch : [132/200] | Step : [300/313] | Loss : 0.0005497150123119354 \n",
            "Epoch : 132 | Loss : 0.015522430677715608 | Training Accuracy : 99.48083067092651% | Learning rate : 0.001\n",
            "Epoch 132 | Validation Accuracy 91.54469936708861%\n",
            "Epoch : [133/200] | Step : [100/313] | Loss : 0.010042018257081509 \n",
            "Epoch : [133/200] | Step : [200/313] | Loss : 0.003023927565664053 \n",
            "Epoch : [133/200] | Step : [300/313] | Loss : 0.0012211563298478723 \n",
            "Epoch : 133 | Loss : 0.010810691306443578 | Training Accuracy : 99.65555111821087% | Learning rate : 0.001\n",
            "Epoch 133 | Validation Accuracy 92.04905063291139%\n",
            "Epoch : [134/200] | Step : [100/313] | Loss : 0.05645247921347618 \n",
            "Epoch : [134/200] | Step : [200/313] | Loss : 0.03952651843428612 \n",
            "Epoch : [134/200] | Step : [300/313] | Loss : 0.014990358613431454 \n",
            "Epoch : 134 | Loss : 0.013553375289637815 | Training Accuracy : 99.56569488817891% | Learning rate : 0.001\n",
            "Epoch 134 | Validation Accuracy 91.56447784810126%\n",
            "Epoch : [135/200] | Step : [100/313] | Loss : 0.035800084471702576 \n",
            "Epoch : [135/200] | Step : [200/313] | Loss : 0.053685761988162994 \n",
            "Epoch : [135/200] | Step : [300/313] | Loss : 0.003268557135015726 \n",
            "Epoch : 135 | Loss : 0.012830828197258405 | Training Accuracy : 99.598142971246% | Learning rate : 0.001\n",
            "Epoch 135 | Validation Accuracy 90.91178797468355%\n",
            "Epoch : [136/200] | Step : [100/313] | Loss : 0.00046954333083704114 \n",
            "Epoch : [136/200] | Step : [200/313] | Loss : 0.011199800297617912 \n",
            "Epoch : [136/200] | Step : [300/313] | Loss : 0.003232137532904744 \n",
            "Epoch : 136 | Loss : 0.011937369324090986 | Training Accuracy : 99.58566293929712% | Learning rate : 0.001\n",
            "Epoch 136 | Validation Accuracy 91.41613924050634%\n",
            "Epoch : [137/200] | Step : [100/313] | Loss : 0.01596098020672798 \n",
            "Epoch : [137/200] | Step : [200/313] | Loss : 0.015785394236445427 \n",
            "Epoch : [137/200] | Step : [300/313] | Loss : 0.0002570037613622844 \n",
            "Epoch : 137 | Loss : 0.011307242324183578 | Training Accuracy : 99.62559904153355% | Learning rate : 0.001\n",
            "Epoch 137 | Validation Accuracy 91.44580696202532%\n",
            "Epoch : [138/200] | Step : [100/313] | Loss : 0.01634584367275238 \n",
            "Epoch : [138/200] | Step : [200/313] | Loss : 0.009854343719780445 \n",
            "Epoch : [138/200] | Step : [300/313] | Loss : 0.0017868359573185444 \n",
            "Epoch : 138 | Loss : 0.014643650967441796 | Training Accuracy : 99.50828674121406% | Learning rate : 0.001\n",
            "Epoch 138 | Validation Accuracy 91.30735759493672%\n",
            "Epoch : [139/200] | Step : [100/313] | Loss : 0.00014840130461379886 \n",
            "Epoch : [139/200] | Step : [200/313] | Loss : 0.007315784227102995 \n",
            "Epoch : [139/200] | Step : [300/313] | Loss : 0.001973638543859124 \n",
            "Epoch : 139 | Loss : 0.010562614514948072 | Training Accuracy : 99.66054313099042% | Learning rate : 0.001\n",
            "Epoch 139 | Validation Accuracy 91.63370253164557%\n",
            "Epoch : [140/200] | Step : [100/313] | Loss : 0.0014037906657904387 \n",
            "Epoch : [140/200] | Step : [200/313] | Loss : 0.001178157515823841 \n",
            "Epoch : [140/200] | Step : [300/313] | Loss : 0.014599685557186604 \n",
            "Epoch : 140 | Loss : 0.013832814244212384 | Training Accuracy : 99.52326277955271% | Learning rate : 0.001\n",
            "Epoch 140 | Validation Accuracy 91.50514240506328%\n",
            "Epoch : [141/200] | Step : [100/313] | Loss : 0.03528068587183952 \n",
            "Epoch : [141/200] | Step : [200/313] | Loss : 0.00028293824288994074 \n",
            "Epoch : [141/200] | Step : [300/313] | Loss : 0.001247361651621759 \n",
            "Epoch : 141 | Loss : 0.011136768371820415 | Training Accuracy : 99.62310303514377% | Learning rate : 0.001\n",
            "Epoch 141 | Validation Accuracy 91.39636075949366%\n",
            "Epoch : [142/200] | Step : [100/313] | Loss : 0.0013107175473123789 \n",
            "Epoch : [142/200] | Step : [200/313] | Loss : 0.005916665308177471 \n",
            "Epoch : [142/200] | Step : [300/313] | Loss : 0.01899712160229683 \n",
            "Epoch : 142 | Loss : 0.012243743947349688 | Training Accuracy : 99.60063897763578% | Learning rate : 0.001\n",
            "Epoch 142 | Validation Accuracy 91.18868670886076%\n",
            "Epoch : [143/200] | Step : [100/313] | Loss : 0.02024775557219982 \n",
            "Epoch : [143/200] | Step : [200/313] | Loss : 0.0017456953646615148 \n",
            "Epoch : [143/200] | Step : [300/313] | Loss : 0.05022840201854706 \n",
            "Epoch : 143 | Loss : 0.011670082903406865 | Training Accuracy : 99.60063897763578% | Learning rate : 0.001\n",
            "Epoch 143 | Validation Accuracy 91.72270569620254%\n",
            "Epoch : [144/200] | Step : [100/313] | Loss : 0.0025938383769243956 \n",
            "Epoch : [144/200] | Step : [200/313] | Loss : 0.0026682624593377113 \n",
            "Epoch : [144/200] | Step : [300/313] | Loss : 0.000976316980086267 \n",
            "Epoch : 144 | Loss : 0.01368588411881787 | Training Accuracy : 99.53324680511182% | Learning rate : 0.001\n",
            "Epoch 144 | Validation Accuracy 91.74248417721519%\n",
            "Epoch : [145/200] | Step : [100/313] | Loss : 0.02135687880218029 \n",
            "Epoch : [145/200] | Step : [200/313] | Loss : 0.00044829497346654534 \n",
            "Epoch : [145/200] | Step : [300/313] | Loss : 0.0019406613428145647 \n",
            "Epoch : 145 | Loss : 0.010936986686006863 | Training Accuracy : 99.65305511182109% | Learning rate : 0.001\n",
            "Epoch 145 | Validation Accuracy 91.89082278481013%\n",
            "Epoch : [146/200] | Step : [100/313] | Loss : 0.007241709157824516 \n",
            "Epoch : [146/200] | Step : [200/313] | Loss : 0.05214419215917587 \n",
            "Epoch : [146/200] | Step : [300/313] | Loss : 0.003059159033000469 \n",
            "Epoch : 146 | Loss : 0.010387498965684382 | Training Accuracy : 99.64806309904152% | Learning rate : 0.001\n",
            "Epoch 146 | Validation Accuracy 91.85126582278481%\n",
            "Epoch : [147/200] | Step : [100/313] | Loss : 0.004578752908855677 \n",
            "Epoch : [147/200] | Step : [200/313] | Loss : 0.000752288440708071 \n",
            "Epoch : [147/200] | Step : [300/313] | Loss : 0.007038466166704893 \n",
            "Epoch : 147 | Loss : 0.00983971944513036 | Training Accuracy : 99.66803115015975% | Learning rate : 0.001\n",
            "Epoch 147 | Validation Accuracy 91.96004746835443%\n",
            "Epoch : [148/200] | Step : [100/313] | Loss : 0.021155795082449913 \n",
            "Epoch : [148/200] | Step : [200/313] | Loss : 0.02650434710085392 \n",
            "Epoch : [148/200] | Step : [300/313] | Loss : 0.0014149309135973454 \n",
            "Epoch : 148 | Loss : 0.014344964747892888 | Training Accuracy : 99.50828674121406% | Learning rate : 0.001\n",
            "Epoch 148 | Validation Accuracy 91.7128164556962%\n",
            "Epoch : [149/200] | Step : [100/313] | Loss : 0.0010743014281615615 \n",
            "Epoch : [149/200] | Step : [200/313] | Loss : 0.004928373731672764 \n",
            "Epoch : [149/200] | Step : [300/313] | Loss : 0.00948011688888073 \n",
            "Epoch : 149 | Loss : 0.010596779236239352 | Training Accuracy : 99.61062300319489% | Learning rate : 0.001\n",
            "Epoch 149 | Validation Accuracy 92.10838607594937%\n",
            "Epoch : [150/200] | Step : [100/313] | Loss : 0.0010334837716072798 \n",
            "Epoch : [150/200] | Step : [200/313] | Loss : 0.003036128357052803 \n",
            "Epoch : [150/200] | Step : [300/313] | Loss : 0.19566315412521362 \n",
            "Epoch : 150 | Loss : 0.04404181652306653 | Training Accuracy : 99.10892571884983% | Learning rate : 0.001\n",
            "Epoch 150 | Validation Accuracy 87.94501582278481%\n",
            "Epoch : [151/200] | Step : [100/313] | Loss : 0.0021386072039604187 \n",
            "Epoch : [151/200] | Step : [200/313] | Loss : 0.026317214593291283 \n",
            "Epoch : [151/200] | Step : [300/313] | Loss : 0.007555136922746897 \n",
            "Epoch : 151 | Loss : 0.026894964428005604 | Training Accuracy : 99.07647763578275% | Learning rate : 0.001\n",
            "Epoch 151 | Validation Accuracy 91.90071202531645%\n",
            "Epoch : [152/200] | Step : [100/313] | Loss : 0.0012076563434675336 \n",
            "Epoch : [152/200] | Step : [200/313] | Loss : 0.00805981457233429 \n",
            "Epoch : [152/200] | Step : [300/313] | Loss : 0.014745672233402729 \n",
            "Epoch : 152 | Loss : 0.01086300306389266 | Training Accuracy : 99.64307108626198% | Learning rate : 0.001\n",
            "Epoch 152 | Validation Accuracy 92.27650316455697%\n",
            "Epoch : [153/200] | Step : [100/313] | Loss : 0.002036699326708913 \n",
            "Epoch : [153/200] | Step : [200/313] | Loss : 0.002889661816880107 \n",
            "Epoch : [153/200] | Step : [300/313] | Loss : 0.0016211631009355187 \n",
            "Epoch : 153 | Loss : 0.005326667550954776 | Training Accuracy : 99.83775958466452% | Learning rate : 0.001\n",
            "Epoch 153 | Validation Accuracy 92.20727848101265%\n",
            "Epoch : [154/200] | Step : [100/313] | Loss : 0.004662463907152414 \n",
            "Epoch : [154/200] | Step : [200/313] | Loss : 0.0027935225516557693 \n",
            "Epoch : [154/200] | Step : [300/313] | Loss : 0.00033629979589022696 \n",
            "Epoch : 154 | Loss : 0.005334618507409111 | Training Accuracy : 99.80281549520767% | Learning rate : 0.001\n",
            "Epoch 154 | Validation Accuracy 92.38528481012658%\n",
            "Saving the model...\n",
            "Epoch : [155/200] | Step : [100/313] | Loss : 0.024371979758143425 \n",
            "Epoch : [155/200] | Step : [200/313] | Loss : 0.0014720887411385775 \n",
            "Epoch : [155/200] | Step : [300/313] | Loss : 0.01875949092209339 \n",
            "Epoch : 155 | Loss : 0.007690721406106604 | Training Accuracy : 99.75039936102237% | Learning rate : 0.001\n",
            "Epoch 155 | Validation Accuracy 92.1182753164557%\n",
            "Epoch : [156/200] | Step : [100/313] | Loss : 0.00023045443231239915 \n",
            "Epoch : [156/200] | Step : [200/313] | Loss : 0.008155327290296555 \n",
            "Epoch : [156/200] | Step : [300/313] | Loss : 0.004160681273788214 \n",
            "Epoch : 156 | Loss : 0.007603171437845034 | Training Accuracy : 99.75539137380191% | Learning rate : 0.001\n",
            "Epoch 156 | Validation Accuracy 91.90071202531645%\n",
            "Epoch : [157/200] | Step : [100/313] | Loss : 0.003517107805237174 \n",
            "Epoch : [157/200] | Step : [200/313] | Loss : 0.0007550166337750852 \n",
            "Epoch : [157/200] | Step : [300/313] | Loss : 0.00120240927208215 \n",
            "Epoch : 157 | Loss : 0.011921183415795506 | Training Accuracy : 99.62809504792332% | Learning rate : 0.001\n",
            "Epoch 157 | Validation Accuracy 91.9501582278481%\n",
            "Epoch : [158/200] | Step : [100/313] | Loss : 0.00020841242803726345 \n",
            "Epoch : [158/200] | Step : [200/313] | Loss : 0.004329239949584007 \n",
            "Epoch : [158/200] | Step : [300/313] | Loss : 0.002123074373230338 \n",
            "Epoch : 158 | Loss : 0.0096125495509654 | Training Accuracy : 99.68550319488818% | Learning rate : 0.001\n",
            "Epoch 158 | Validation Accuracy 91.55458860759494%\n",
            "Epoch : [159/200] | Step : [100/313] | Loss : 0.014227635227143764 \n",
            "Epoch : [159/200] | Step : [200/313] | Loss : 0.0008098281687125564 \n",
            "Epoch : [159/200] | Step : [300/313] | Loss : 0.002661369973793626 \n",
            "Epoch : 159 | Loss : 0.01058658542140434 | Training Accuracy : 99.68051118210862% | Learning rate : 0.001\n",
            "Epoch 159 | Validation Accuracy 92.06882911392405%\n",
            "Epoch : [160/200] | Step : [100/313] | Loss : 0.00205337000079453 \n",
            "Epoch : [160/200] | Step : [200/313] | Loss : 0.0006732134497724473 \n",
            "Epoch : [160/200] | Step : [300/313] | Loss : 0.0007574769551865757 \n",
            "Epoch : 160 | Loss : 0.00803070609938655 | Training Accuracy : 99.75788738019169% | Learning rate : 0.001\n",
            "Epoch 160 | Validation Accuracy 92.24683544303798%\n",
            "Epoch : [161/200] | Step : [100/313] | Loss : 0.015326270833611488 \n",
            "Epoch : [161/200] | Step : [200/313] | Loss : 0.03596105799078941 \n",
            "Epoch : [161/200] | Step : [300/313] | Loss : 0.00043977174209430814 \n",
            "Epoch : 161 | Loss : 0.011072855940479718 | Training Accuracy : 99.64307108626198% | Learning rate : 0.001\n",
            "Epoch 161 | Validation Accuracy 91.20846518987342%\n",
            "Epoch : [162/200] | Step : [100/313] | Loss : 0.02606164664030075 \n",
            "Epoch : [162/200] | Step : [200/313] | Loss : 0.006628901232033968 \n",
            "Epoch : [162/200] | Step : [300/313] | Loss : 0.0021287158597260714 \n",
            "Epoch : 162 | Loss : 0.010050987436940273 | Training Accuracy : 99.6630391373802% | Learning rate : 0.001\n",
            "Epoch 162 | Validation Accuracy 91.63370253164557%\n",
            "Epoch : [163/200] | Step : [100/313] | Loss : 0.01077212207019329 \n",
            "Epoch : [163/200] | Step : [200/313] | Loss : 0.017025358974933624 \n",
            "Epoch : [163/200] | Step : [300/313] | Loss : 0.004418622702360153 \n",
            "Epoch : 163 | Loss : 0.011957114896342417 | Training Accuracy : 99.59564696485623% | Learning rate : 0.001\n",
            "Epoch 163 | Validation Accuracy 91.90071202531645%\n",
            "Epoch : [164/200] | Step : [100/313] | Loss : 0.012536508962512016 \n",
            "Epoch : [164/200] | Step : [200/313] | Loss : 0.006092245690524578 \n",
            "Epoch : [164/200] | Step : [300/313] | Loss : 0.005290292203426361 \n",
            "Epoch : 164 | Loss : 0.008936056219216714 | Training Accuracy : 99.67052715654951% | Learning rate : 0.001\n",
            "Epoch 164 | Validation Accuracy 91.65348101265823%\n",
            "Epoch : [165/200] | Step : [100/313] | Loss : 0.000940995174460113 \n",
            "Epoch : [165/200] | Step : [200/313] | Loss : 0.0037689912132918835 \n",
            "Epoch : [165/200] | Step : [300/313] | Loss : 0.007648094091564417 \n",
            "Epoch : 165 | Loss : 0.00885772410098483 | Training Accuracy : 99.7154552715655% | Learning rate : 0.001\n",
            "Epoch 165 | Validation Accuracy 91.28757911392405%\n",
            "Epoch : [166/200] | Step : [100/313] | Loss : 0.008192374370992184 \n",
            "Epoch : [166/200] | Step : [200/313] | Loss : 0.027657944709062576 \n",
            "Epoch : [166/200] | Step : [300/313] | Loss : 0.002499223919585347 \n",
            "Epoch : 166 | Loss : 0.015336857707973885 | Training Accuracy : 99.51078274760383% | Learning rate : 0.001\n",
            "Epoch 166 | Validation Accuracy 91.96004746835443%\n",
            "Epoch : [167/200] | Step : [100/313] | Loss : 0.02641311287879944 \n",
            "Epoch : [167/200] | Step : [200/313] | Loss : 0.0005321408389136195 \n",
            "Epoch : [167/200] | Step : [300/313] | Loss : 0.004130598157644272 \n",
            "Epoch : 167 | Loss : 0.012318190687373965 | Training Accuracy : 99.61561501597444% | Learning rate : 0.001\n",
            "Epoch 167 | Validation Accuracy 91.74248417721519%\n",
            "Epoch : [168/200] | Step : [100/313] | Loss : 0.000430943735409528 \n",
            "Epoch : [168/200] | Step : [200/313] | Loss : 0.009021589532494545 \n",
            "Epoch : [168/200] | Step : [300/313] | Loss : 0.000513202219735831 \n",
            "Epoch : 168 | Loss : 0.008923753143124822 | Training Accuracy : 99.70047923322683% | Learning rate : 0.001\n",
            "Epoch 168 | Validation Accuracy 91.9501582278481%\n",
            "Epoch : [169/200] | Step : [100/313] | Loss : 0.03343787416815758 \n",
            "Epoch : [169/200] | Step : [200/313] | Loss : 0.02499302476644516 \n",
            "Epoch : [169/200] | Step : [300/313] | Loss : 0.006738805677741766 \n",
            "Epoch : 169 | Loss : 0.008298325412705396 | Training Accuracy : 99.75539137380191% | Learning rate : 0.001\n",
            "Epoch 169 | Validation Accuracy 92.34572784810126%\n",
            "Epoch : [170/200] | Step : [100/313] | Loss : 3.99612654291559e-05 \n",
            "Epoch : [170/200] | Step : [200/313] | Loss : 0.0010427437955513597 \n",
            "Epoch : [170/200] | Step : [300/313] | Loss : 0.0010178735246881843 \n",
            "Epoch : 170 | Loss : 0.008380928434429787 | Training Accuracy : 99.69548722044729% | Learning rate : 0.001\n",
            "Epoch 170 | Validation Accuracy 91.41613924050634%\n",
            "Epoch : [171/200] | Step : [100/313] | Loss : 0.008629875257611275 \n",
            "Epoch : [171/200] | Step : [200/313] | Loss : 0.008378852158784866 \n",
            "Epoch : [171/200] | Step : [300/313] | Loss : 0.0386577732861042 \n",
            "Epoch : 171 | Loss : 0.012614872814926018 | Training Accuracy : 99.5457268370607% | Learning rate : 0.001\n",
            "Epoch 171 | Validation Accuracy 92.19738924050634%\n",
            "Epoch : [172/200] | Step : [100/313] | Loss : 0.0003578028699848801 \n",
            "Epoch : [172/200] | Step : [200/313] | Loss : 0.0008479549433104694 \n",
            "Epoch : [172/200] | Step : [300/313] | Loss : 0.01975010149180889 \n",
            "Epoch : 172 | Loss : 0.008210172223739145 | Training Accuracy : 99.71795127795528% | Learning rate : 0.001\n",
            "Epoch 172 | Validation Accuracy 91.75237341772153%\n",
            "Epoch : [173/200] | Step : [100/313] | Loss : 0.0004816821019630879 \n",
            "Epoch : [173/200] | Step : [200/313] | Loss : 0.0021614134311676025 \n",
            "Epoch : [173/200] | Step : [300/313] | Loss : 0.022982442751526833 \n",
            "Epoch : 173 | Loss : 0.007868254817791652 | Training Accuracy : 99.70796725239617% | Learning rate : 0.001\n",
            "Epoch 173 | Validation Accuracy 91.59414556962025%\n",
            "Epoch : [174/200] | Step : [100/313] | Loss : 0.000178578746272251 \n",
            "Epoch : [174/200] | Step : [200/313] | Loss : 0.0011356562608852983 \n",
            "Epoch : [174/200] | Step : [300/313] | Loss : 0.010681625455617905 \n",
            "Epoch : 174 | Loss : 0.009693060269993161 | Training Accuracy : 99.6730231629393% | Learning rate : 0.001\n",
            "Epoch 174 | Validation Accuracy 91.66337025316456%\n",
            "Epoch : [175/200] | Step : [100/313] | Loss : 0.015984687954187393 \n",
            "Epoch : [175/200] | Step : [200/313] | Loss : 0.0004120142839383334 \n",
            "Epoch : [175/200] | Step : [300/313] | Loss : 0.002406254643574357 \n",
            "Epoch : 175 | Loss : 0.008789967318434516 | Training Accuracy : 99.69049520766772% | Learning rate : 0.001\n",
            "Epoch 175 | Validation Accuracy 91.73259493670885%\n",
            "Epoch : [176/200] | Step : [100/313] | Loss : 0.0012269458966329694 \n",
            "Epoch : [176/200] | Step : [200/313] | Loss : 0.00317497574724257 \n",
            "Epoch : [176/200] | Step : [300/313] | Loss : 0.0006208331906236708 \n",
            "Epoch : 176 | Loss : 0.009229642700268359 | Training Accuracy : 99.7154552715655% | Learning rate : 0.001\n",
            "Epoch 176 | Validation Accuracy 92.10838607594937%\n",
            "Epoch : [177/200] | Step : [100/313] | Loss : 0.012324456125497818 \n",
            "Epoch : [177/200] | Step : [200/313] | Loss : 0.01847919076681137 \n",
            "Epoch : [177/200] | Step : [300/313] | Loss : 0.0010513481684029102 \n",
            "Epoch : 177 | Loss : 0.010060453430354575 | Training Accuracy : 99.65305511182109% | Learning rate : 0.001\n",
            "Epoch 177 | Validation Accuracy 91.44580696202532%\n",
            "Epoch : [178/200] | Step : [100/313] | Loss : 0.009269103407859802 \n",
            "Epoch : [178/200] | Step : [200/313] | Loss : 0.006702831014990807 \n",
            "Epoch : [178/200] | Step : [300/313] | Loss : 0.001053722808137536 \n",
            "Epoch : 178 | Loss : 0.008390453482317213 | Training Accuracy : 99.6929912140575% | Learning rate : 0.001\n",
            "Epoch 178 | Validation Accuracy 91.77215189873418%\n",
            "Epoch : [179/200] | Step : [100/313] | Loss : 0.028638608753681183 \n",
            "Epoch : [179/200] | Step : [200/313] | Loss : 0.008851595222949982 \n",
            "Epoch : [179/200] | Step : [300/313] | Loss : 0.0013839062303304672 \n",
            "Epoch : 179 | Loss : 0.00893304475146044 | Training Accuracy : 99.73292731629392% | Learning rate : 0.001\n",
            "Epoch 179 | Validation Accuracy 91.8117088607595%\n",
            "Epoch : [180/200] | Step : [100/313] | Loss : 0.0015482333255931735 \n",
            "Epoch : [180/200] | Step : [200/313] | Loss : 0.06947080045938492 \n",
            "Epoch : [180/200] | Step : [300/313] | Loss : 0.003033359069377184 \n",
            "Epoch : 180 | Loss : 0.013478081379672133 | Training Accuracy : 99.55820686900958% | Learning rate : 0.001\n",
            "Epoch 180 | Validation Accuracy 91.83148734177216%\n",
            "Epoch : [181/200] | Step : [100/313] | Loss : 0.0020026478450745344 \n",
            "Epoch : [181/200] | Step : [200/313] | Loss : 0.015127986669540405 \n",
            "Epoch : [181/200] | Step : [300/313] | Loss : 0.002826472045853734 \n",
            "Epoch : 181 | Loss : 0.009012436751690868 | Training Accuracy : 99.73043130990416% | Learning rate : 0.001\n",
            "Epoch 181 | Validation Accuracy 91.85126582278481%\n",
            "Epoch : [182/200] | Step : [100/313] | Loss : 0.006070760078728199 \n",
            "Epoch : [182/200] | Step : [200/313] | Loss : 0.0005570958601310849 \n",
            "Epoch : [182/200] | Step : [300/313] | Loss : 0.03225906565785408 \n",
            "Epoch : 182 | Loss : 0.007649513388068576 | Training Accuracy : 99.73791932907349% | Learning rate : 0.001\n",
            "Epoch 182 | Validation Accuracy 91.58425632911393%\n",
            "Epoch : [183/200] | Step : [100/313] | Loss : 0.010799596086144447 \n",
            "Epoch : [183/200] | Step : [200/313] | Loss : 0.059975698590278625 \n",
            "Epoch : [183/200] | Step : [300/313] | Loss : 0.01168458629399538 \n",
            "Epoch : 183 | Loss : 0.008785084834650193 | Training Accuracy : 99.6929912140575% | Learning rate : 0.001\n",
            "Epoch 183 | Validation Accuracy 91.80181962025317%\n",
            "Epoch : [184/200] | Step : [100/313] | Loss : 0.0018655018648132682 \n",
            "Epoch : [184/200] | Step : [200/313] | Loss : 0.0011961408890783787 \n",
            "Epoch : [184/200] | Step : [300/313] | Loss : 0.001953494967892766 \n",
            "Epoch : 184 | Loss : 0.008760685749316087 | Training Accuracy : 99.73292731629392% | Learning rate : 0.001\n",
            "Epoch 184 | Validation Accuracy 91.91060126582279%\n",
            "Epoch : [185/200] | Step : [100/313] | Loss : 0.031913768500089645 \n",
            "Epoch : [185/200] | Step : [200/313] | Loss : 0.03225070238113403 \n",
            "Epoch : [185/200] | Step : [300/313] | Loss : 0.002686253748834133 \n",
            "Epoch : 185 | Loss : 0.009561584223466837 | Training Accuracy : 99.67801517571885% | Learning rate : 0.001\n",
            "Epoch 185 | Validation Accuracy 92.15783227848101%\n",
            "Epoch : [186/200] | Step : [100/313] | Loss : 0.0005705429357476532 \n",
            "Epoch : [186/200] | Step : [200/313] | Loss : 0.0009104131604544818 \n",
            "Epoch : [186/200] | Step : [300/313] | Loss : 0.0008818858186714351 \n",
            "Epoch : 186 | Loss : 0.007780418718231287 | Training Accuracy : 99.77036741214057% | Learning rate : 0.001\n",
            "Epoch 186 | Validation Accuracy 90.87223101265823%\n",
            "Epoch : [187/200] | Step : [100/313] | Loss : 0.002161091659218073 \n",
            "Epoch : [187/200] | Step : [200/313] | Loss : 0.0011948171304538846 \n",
            "Epoch : [187/200] | Step : [300/313] | Loss : 0.0026614447124302387 \n",
            "Epoch : 187 | Loss : 0.00923291267287849 | Training Accuracy : 99.68051118210862% | Learning rate : 0.001\n",
            "Epoch 187 | Validation Accuracy 91.74248417721519%\n",
            "Epoch : [188/200] | Step : [100/313] | Loss : 0.0024295980110764503 \n",
            "Epoch : [188/200] | Step : [200/313] | Loss : 0.0014000983210280538 \n",
            "Epoch : [188/200] | Step : [300/313] | Loss : 0.004884425085037947 \n",
            "Epoch : 188 | Loss : 0.008905397955871808 | Training Accuracy : 99.7054712460064% | Learning rate : 0.001\n",
            "Epoch 188 | Validation Accuracy 91.94026898734177%\n",
            "Epoch : [189/200] | Step : [100/313] | Loss : 0.017270846292376518 \n",
            "Epoch : [189/200] | Step : [200/313] | Loss : 0.008412107825279236 \n",
            "Epoch : [189/200] | Step : [300/313] | Loss : 0.006940552499145269 \n",
            "Epoch : 189 | Loss : 0.011337537435697022 | Training Accuracy : 99.620607028754% | Learning rate : 0.001\n",
            "Epoch 189 | Validation Accuracy 92.17761075949366%\n",
            "Epoch : [190/200] | Step : [100/313] | Loss : 0.006786773446947336 \n",
            "Epoch : [190/200] | Step : [200/313] | Loss : 0.00011708121019182727 \n",
            "Epoch : [190/200] | Step : [300/313] | Loss : 0.0016607976285740733 \n",
            "Epoch : 190 | Loss : 0.008955841480340818 | Training Accuracy : 99.7254392971246% | Learning rate : 0.001\n",
            "Epoch 190 | Validation Accuracy 91.74248417721519%\n",
            "Epoch : [191/200] | Step : [100/313] | Loss : 0.006606096401810646 \n",
            "Epoch : [191/200] | Step : [200/313] | Loss : 0.006030213087797165 \n",
            "Epoch : [191/200] | Step : [300/313] | Loss : 0.005773954093456268 \n",
            "Epoch : 191 | Loss : 0.012310077079885882 | Training Accuracy : 99.62310303514377% | Learning rate : 0.001\n",
            "Epoch 191 | Validation Accuracy 91.83148734177216%\n",
            "Epoch : [192/200] | Step : [100/313] | Loss : 0.013506983406841755 \n",
            "Epoch : [192/200] | Step : [200/313] | Loss : 0.006827476434409618 \n",
            "Epoch : [192/200] | Step : [300/313] | Loss : 0.00048642070032656193 \n",
            "Epoch : 192 | Loss : 0.008034832403565884 | Training Accuracy : 99.74041533546327% | Learning rate : 0.001\n",
            "Epoch 192 | Validation Accuracy 92.10838607594937%\n",
            "Epoch : [193/200] | Step : [100/313] | Loss : 0.0005123444134369493 \n",
            "Epoch : [193/200] | Step : [200/313] | Loss : 0.0013181621907278895 \n",
            "Epoch : [193/200] | Step : [300/313] | Loss : 0.00011137039109598845 \n",
            "Epoch : 193 | Loss : 0.007539512242071335 | Training Accuracy : 99.74041533546327% | Learning rate : 0.001\n",
            "Epoch 193 | Validation Accuracy 91.82159810126582%\n",
            "Epoch : [194/200] | Step : [100/313] | Loss : 0.00036487344186753035 \n",
            "Epoch : [194/200] | Step : [200/313] | Loss : 0.00083356216782704 \n",
            "Epoch : [194/200] | Step : [300/313] | Loss : 0.012688745744526386 \n",
            "Epoch : 194 | Loss : 0.005773765067506218 | Training Accuracy : 99.80780750798722% | Learning rate : 0.001\n",
            "Epoch 194 | Validation Accuracy 92.45450949367088%\n",
            "Saving the model...\n",
            "Epoch : [195/200] | Step : [100/313] | Loss : 0.0098562715575099 \n",
            "Epoch : [195/200] | Step : [200/313] | Loss : 0.0006010818760842085 \n",
            "Epoch : [195/200] | Step : [300/313] | Loss : 0.0013766736956313252 \n",
            "Epoch : 195 | Loss : 0.008331095246552005 | Training Accuracy : 99.7354233226837% | Learning rate : 0.001\n",
            "Epoch 195 | Validation Accuracy 91.98971518987342%\n",
            "Epoch : [196/200] | Step : [100/313] | Loss : 0.000925071828532964 \n",
            "Epoch : [196/200] | Step : [200/313] | Loss : 0.06849820166826248 \n",
            "Epoch : [196/200] | Step : [300/313] | Loss : 0.0016831181710585952 \n",
            "Epoch : 196 | Loss : 0.016095107247562558 | Training Accuracy : 99.5457268370607% | Learning rate : 0.001\n",
            "Epoch 196 | Validation Accuracy 91.70292721518987%\n",
            "Epoch : [197/200] | Step : [100/313] | Loss : 0.014597184956073761 \n",
            "Epoch : [197/200] | Step : [200/313] | Loss : 0.00702996551990509 \n",
            "Epoch : [197/200] | Step : [300/313] | Loss : 0.00019102309306617826 \n",
            "Epoch : 197 | Loss : 0.00813276009133793 | Training Accuracy : 99.69049520766772% | Learning rate : 0.001\n",
            "Epoch 197 | Validation Accuracy 91.65348101265823%\n",
            "Epoch : [198/200] | Step : [100/313] | Loss : 0.00026478126528672874 \n",
            "Epoch : [198/200] | Step : [200/313] | Loss : 0.005104380194097757 \n",
            "Epoch : [198/200] | Step : [300/313] | Loss : 0.0005563498707488179 \n",
            "Epoch : 198 | Loss : 0.005689116065480974 | Training Accuracy : 99.79782348242811% | Learning rate : 0.001\n",
            "Epoch 198 | Validation Accuracy 92.09849683544303%\n",
            "Epoch : [199/200] | Step : [100/313] | Loss : 0.001221353653818369 \n",
            "Epoch : [199/200] | Step : [200/313] | Loss : 0.014930592849850655 \n",
            "Epoch : [199/200] | Step : [300/313] | Loss : 0.00310068903490901 \n",
            "Epoch : 199 | Loss : 0.012172221503245697 | Training Accuracy : 99.55321485623003% | Learning rate : 0.001\n",
            "Epoch 199 | Validation Accuracy 91.9501582278481%\n",
            "Epoch : [200/200] | Step : [100/313] | Loss : 0.003008265746757388 \n",
            "Epoch : [200/200] | Step : [200/313] | Loss : 0.00375990173779428 \n",
            "Epoch : [200/200] | Step : [300/313] | Loss : 0.0017054759664461017 \n",
            "Epoch : 200 | Loss : 0.0062399988994420764 | Training Accuracy : 99.78284744408946% | Learning rate : 0.001\n",
            "Epoch 200 | Validation Accuracy 92.38528481012658%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#Train Vs Validation loss\n",
        "df = pd.DataFrame({'Training Loss':train_loss, 'Validation Loss':validation_loss})\n",
        "df.plot(linewidth=4, alpha=0.7, figsize=(15,7), label='Loss')\n",
        "plt.xlim([0,10])\n",
        "# plt.ylim(-20,100)\n",
        "plt.title('Training vs Validation Loss per Epoch', fontsize=22)\n",
        "plt.grid(axis='y', alpha=.5)\n",
        "plt.yticks(fontsize=12, alpha=.7)\n",
        "plt.xticks(fontsize=12, alpha=.7)\n",
        "plt.xlabel('Epoch', fontsize=18, alpha=.7)\n",
        "plt.ylabel('Loss Value', fontsize=18, alpha=.7)\n",
        "# Lighten borders\n",
        "plt.gca().spines[\"top\"].set_alpha(.0)\n",
        "plt.gca().spines[\"bottom\"].set_alpha(.3)\n",
        "plt.gca().spines[\"right\"].set_alpha(.0)\n",
        "plt.gca().spines[\"left\"].set_alpha(.3)\n",
        "\n",
        "plt.legend(loc='upper center')\n",
        "plt.show()\n",
        "\n",
        "# epoch and accuracy over val/test set\n",
        "df = pd.DataFrame({'Training Accuracy':train_acc, 'Validation Accuracy':validation_acc})\n",
        "df.plot(linewidth=4, alpha=0.7, figsize=(15,7), label='Loss')\n",
        "plt.xlim([0,10])\n",
        "# plt.ylim(-20,100)\n",
        "plt.title('Training vs Validation Accuracy Per Epoch', fontsize=22)\n",
        "plt.grid(axis='y', alpha=.5)\n",
        "plt.yticks(fontsize=12, alpha=.7)\n",
        "plt.xticks(fontsize=12, alpha=.7)\n",
        "plt.xlabel('Epoch', fontsize=18, alpha=.7)\n",
        "plt.ylabel('Accuracy Percentage', fontsize=18, alpha=.7)\n",
        "# Lighten borders\n",
        "plt.gca().spines[\"top\"].set_alpha(.0)\n",
        "plt.gca().spines[\"bottom\"].set_alpha(.3)\n",
        "plt.gca().spines[\"right\"].set_alpha(.0)\n",
        "plt.gca().spines[\"left\"].set_alpha(.3)\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "4DiwsaZ8X6Cf",
        "outputId": "a9dd5360-2caa-46b7-d849-dbfb7e32cde7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader, BEST_MODEL):\n",
        "   model.load_state_dict(torch.load(BEST_MODEL))\n",
        "\n",
        "   with torch.no_grad():\n",
        "     correct_predictions = []\n",
        "     testing_acc_scores = []\n",
        "     wrong_predictions = []\n",
        "     all_targets = []\n",
        "     all_preds = []\n",
        "\n",
        "     for images, targets in iter(test_loader):\n",
        "       images = images.to(device)\n",
        "       targets = targets.to(device)\n",
        "       outputs = model(images)\n",
        "      \n",
        "       _, preds = torch.max(outputs, 1)\n",
        "       correct_indicies = (preds == targets).nonzero(as_tuple=True)[0]\n",
        "       c_images = images[correct_indicies]\n",
        "       c_targets = targets[correct_indicies]\n",
        "       c_wrong_preds = preds[correct_indicies]\n",
        "       testing_acc_scores.append(len(correct_indicies)/targets.shape[0])\n",
        "\n",
        "       wrong_indicies = (preds != targets).nonzero(as_tuple=True)[0]\n",
        "       w_images = images[wrong_indicies]\n",
        "       w_targets = targets[wrong_indicies]\n",
        "       w_wrong_preds = preds[wrong_indicies]\n",
        "  \n",
        "       correct_predictions += zip(c_images, c_targets, c_wrong_preds)\n",
        "       wrong_predictions += zip(w_images, w_targets, w_wrong_preds)\n",
        "       all_targets+= zip(targets.cpu().numpy())\n",
        "       all_preds+= zip(preds.cpu().numpy())\n",
        "       \n",
        "\n",
        "     return (sum(testing_acc_scores)/len(testing_acc_scores))*100, correct_predictions, wrong_predictions, all_targets, all_preds\n",
        "          "
      ],
      "metadata": {
        "id": "8Aei1-riX6qM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy, correct_predictions, wrong_predictions, all_targets, all_preds = test_model(ResNet34, test_loader, BEST_MODEL='/content/gdrive/MyDrive/Optimization/Accuracy_92.45450949367088_batchsize_128_lr_0.001.ckpt' )\n"
      ],
      "metadata": {
        "id": "c0ko-0jiX_tK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy of the network on the training dataset: {max(train_acc)}')\n",
        "print(f'Accuracy of the network on the validation dataset: {max(validation_acc)}')\n",
        "print(f'Accuracy of the network on the test dataset: {round(test_accuracy)}')\n",
        "print(len(correct_predictions))\n",
        "print(len(wrong_predictions))\n",
        "print(len(all_preds))\n",
        "print(len(all_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwwb7XxZYCiV",
        "outputId": "06825b72-68d7-4005-d195-bb32c17cc9b0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the training dataset: 99.83775958466452\n",
            "Accuracy of the network on the validation dataset: 92.45450949367088\n",
            "Accuracy of the network on the test dataset: 93\n",
            "9274\n",
            "726\n",
            "10000\n",
            "10000\n"
          ]
        }
      ]
    }
  ]
}